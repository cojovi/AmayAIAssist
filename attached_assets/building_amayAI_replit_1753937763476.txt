Building AmayAI: AI Personal Assistant for Google Workspace
Purpose and Target Use Case
AmayAI is an AI-powered personal assistant web app designed to help employees at cmacroofing.com manage routine tasks and communications. Inspired by the capabilities of Martin (a Y Combinator-backed “Jarvis-style” AI assistant), AmayAI’s purpose is to offload “grunt work” so users can focus on higher-value activities. It will handle things like triaging email, scheduling meetings, setting reminders, and drafting communications on behalf of users, learning their preferences over time to become more helpful. The target use case is busy professionals in the company’s Google Workspace domain who receive lots of emails, juggle meetings, and have many to-dos – AmayAI will act as a 24/7 digital secretary to make their workday more efficient. Unlike Martin which interacts via phone calls or SMS, AmayAI will integrate with the company’s existing tools (Google Workspace and Slack). It will work fully within Google Workspace (Gmail, Calendar, Tasks) using corporate accounts and deliver notifications via Slack direct messages instead of texts or calls. This ensures AmayAI fits naturally into the company’s workflows – for example, reminding users of tasks or meetings by pinging them on Slack, a channel they already use daily. In summary, AmayAI aims to provide Martin-like productivity benefits in a customized, secure way for the cmacroofing.com team.
Core Features and Capabilities
AmayAI’s functionality can be broken down into several core features. Each feature mirrors a capability of the Martin assistant and is implemented through Google Workspace integrations plus an LLM (Large Language Model) layer:
Inbox Triage & Drafting
This is one of AmayAI’s most valuable functions: helping users manage email overload. The assistant will monitor the user’s Gmail inbox and triage incoming messages – for example, by applying labels or moving messages to folders, summarizing long email threads, and even drafting reply emails that the user can quickly approve and send. This is similar to how Martin handles email: it labels and sorts messages, generates a brief summary of threads, and writes suggested replies for the user. The goal is that when a user opens their inbox or AmayAI dashboard, they see a prioritized, summarized view of new emails with quick-action options (like “Send draft reply” or “Snooze”). How it works: Behind the scenes, AmayAI uses the Gmail API to read new messages and an AI model to analyze them. We will enable Gmail push notifications so the backend gets alerted whenever a new email arrives. When an email comes in, AmayAI’s backend will fetch the message via the Gmail API, then call an LLM (such as OpenAI GPT-4) to analyze its content. The LLM will be prompted to do things like: determine the email’s urgency, suggest an appropriate label or folder, produce a one-sentence summary, and draft a few possible replies the user might want to send. For example, if an email is a meeting request, the summary might be “Client X is asking to schedule a project call,” and the drafts might include polite responses. The assistant can then apply a label in Gmail (e.g. “Needs Action” or “Awaiting Reply”) and store the AI-generated summary and replies. These results are surfaced in the web UI for the user to review – the user might click one of the draft replies to send it, or edit it first. By leveraging a GPT-4-class model for this NLP-heavy task, we follow a proven approach (email tools like Superhuman have a similar “AI reply” feature built on OpenAI models). Implementation Steps:
Gmail Webhooks: Set up Gmail API push notifications using users.watch so that AmayAI is notified of new emails in real time. This avoids constant polling and ensures timely triage.
Email Fetch & Analysis: When notified of a new message, call Gmail’s API (messages.get) to retrieve the email content (and possibly thread history). Extract metadata like sender, thread length, existing labels, etc.
LLM Processing: Send a prompt to the LLM (OpenAI GPT or Google Gemini) with the email content and specific instructions. For example: “Summarize this email thread in one sentence, classify its importance (urgent or not), suggest a label or folder, and draft three brief reply options in the user’s tone.” The LLM’s response will contain the summary and draft replies.
Apply Triage Actions: Use Gmail API to apply any label or mark (if we decide on auto-labeling, e.g. mark as “triaged” or move to a folder). Save the AI-generated summary and replies to our database or directly attach them in the UI for the user.
User Approval: In the AmayAI web interface, display the summary and draft responses for each new email. The user can choose to send a draft (in which case the backend will call Gmail API to send it) or modify it. Unused drafts can be discarded. The idea is the user spends seconds to handle an email that would otherwise take minutes to read and respond.
By automating email triage and reply drafting, AmayAI helps users reach “inbox zero” faster. It’s important to let the user be the final decision-maker on sending AI-composed emails (at least initially) to maintain quality and trust. Over time, if confidence grows, some low-risk emails could even be auto-sent. All the heavy lifting here – classification, summarization, generation – is done by the LLM, while all email reading/sending uses the Gmail API with the user’s account (via impersonation).
Calendar Scheduling
AmayAI will serve as a smart scheduling assistant to eliminate the back-and-forth of finding meeting times. In practice, this means if someone needs to schedule a meeting, the user can loop AmayAI into the conversation and it will handle proposing times and creating the calendar event. Martin accomplishes this by having users CC an email address (e.g. martin@domain.com) on scheduling emails; the assistant then replies to the thread with available times and schedules the meeting on everyone’s calendars. We will do the same with AmayAI. For example, if a cmacroofing.com employee is emailing a client to set up a call, they can CC amayai@cmacroofing.com on the email. AmayAI (monitoring that inbox) will recognize the scheduling request, find open slots on the employee’s Google Calendar, and reply-all with a proposed time. Once the time is confirmed, AmayAI will create a Calendar event for all participants. It juggles conflicts and time zones automatically by leveraging Google Calendar’s data. How it works: AmayAI’s backend will utilize the Google Calendar API extensively for this feature. The workflow looks like this: When AmayAI is included in an email thread about scheduling, it will parse the email text to understand the meeting request (who the attendees are, any mentioned times or constraints). We can use an LLM to extract intent and timing from the email conversation (e.g. “Client asks for a meeting next week, 30 minutes”). Next, AmayAI will query everyone’s Google Calendar availability using the freeBusy.query endpoint – this tells us what time slots are free for the user and optionally for other internal participants (for external attendees, we may only know what times the user is free and propose those). The assistant then chooses an optimal slot (the logic can be simple: earliest mutually free slot, within business hours, etc.) and creates a calendar event via the Calendar API. The event will include all attendees’ emails and details from the context (title, location or video call link if needed). AmayAI then sends an email reply to the thread confirming the scheduled meeting time and attaches the calendar invite. This email can come from the assistant’s own address (e.g. amayai@cmacroofing.com) or impersonate the user’s address – but using a dedicated assistant address is clearer to participants. Once done, the event appears on the user’s Google Calendar (and invites are sent to others automatically by Google Calendar). Implementation Steps:
Trigger Detection: Provide an email address for AmayAI (such as amayai@cmacroofing.com) and set it up as a user or alias in Google Workspace. Monitor this mailbox (via Gmail API) for incoming threads. When an email arrives that includes this address (CC/BCC), assume it’s a scheduling request and fetch the thread.
LLM Parsing (Optional): Use an LLM to analyze the email thread for scheduling details – e.g., to find phrases like “next week” or “Monday afternoon” and to identify all participants. This helps interpret any human preferences stated in the emails. (If the request is straightforward or formatted, this step can be simple or rule-based.)
Availability Lookup: Call the Google Calendar API’s FreeBusy query to get open time slots for the involved internal users (at least for the main user on whose behalf we’re scheduling). The service account can also check coworkers’ calendars if needed (provided appropriate access) to propose times when all internal parties are free.
Propose Times via Email: Generate a list of one or two optimal meeting slots (e.g. “How about Tuesday at 3 PM or Wednesday at 10 AM?”). This text can be crafted by the LLM or by a template. Send an email reply in the thread from the assistant (AmayAI’s address) with the proposed times.
Book the Meeting: Once the other party agrees on a slot (they might reply or just accept one of the proposed invites), AmayAI creates the event on the user’s Google Calendar using the Calendar API. It sets the user as the event organizer (or the assistant user, depending on design) and adds all attendees. The Calendar API will automatically email invitations to attendees. AmayAI can then send a final confirmation email like “Meeting confirmed for Tuesday at 3 PM, invite sent.”
Conflict Handling: If none of the proposed times work (or if the user instructs AmayAI via Slack/UI to schedule a meeting with someone), the system may iterate: it could propose new times or use the LLM to negotiate a time. However, for MVP, it’s sufficient to propose a couple of times and let the humans finalize.
This scheduling feature saves users from tedious coordination. Essentially, we turn email threads + Calendar API into a scheduling engine – “cc to schedule” is implemented by combining natural language understanding (to read the request) and programmatic calendar management (to find free times and book events). The heavy logic (finding free slots) is handled by Google Calendar, and the assistant just orchestrates the communication.
Reminders, To-Dos, and Briefings
AmayAI will help users keep track of their tasks and deadlines through integrated reminders and to-do management. Users should be able to quickly create a reminder or task by telling AmayAI (for example, typing in Slack “remind me to call the supplier tomorrow at 9am”). The assistant will record this in the user’s Google Tasks list (or Calendar, as a dated reminder) and then send a Slack DM at the appropriate time to remind the user. In addition, AmayAI can send daily or weekly “briefings” that summarize upcoming events or tasks – similar to Martin’s daily briefing emails, but delivered via Slack or email based on preference. Under the hood, we will utilize Google Tasks API for to-do items and reminders, since Tasks is the built-in task system for Google Workspace. Every user in Google Workspace has their own Tasks lists, and AmayAI can create entries there for any reminders or tasks the user sets. By using Google Tasks, the reminders will also be visible to the user in their Google ecosystem (e.g., in Gmail sidebar or Google Calendar if they show tasks). For time-based reminders, AmayAI will keep track of the due time and then proactively notify the user when it’s time. How it works: There are two main ways reminders get into the system: user-driven and proactive. User-driven reminders are explicit requests (voice or text commands like “Remind me to send the proposal Friday at 3 PM”). We’ll capture these requests either via the web UI (a quick “Add Reminder” form) or via a Slack message to the bot. AmayAI parses the request (likely using an LLM to extract the task and date/time) and creates a new task in the user’s Google Tasks with the due date/time. Proactive reminders come from AmayAI’s own analysis – for example, if it sees an unpaid invoice email, it might create a reminder “Follow up on invoice #123” for next week (after asking the user). In both cases, the task is stored in Google Tasks, and possibly also logged in our database for tracking. When a task’s due time arrives (or a scheduled reminder time hits), AmayAI will send the user a Slack direct message to make sure they see it immediately. (For example: “🔔 Reminder: call the supplier now.”) This replaces the need for sending SMS or making a phone call as Martin might have done. The Slack message can be generated by our backend when the time comes, or we can schedule it in advance using Slack’s API. Once sent, AmayAI can mark the task as “completed” or add a note if appropriate. AmayAI can also provide daily or weekly briefing messages. For instance, every morning at 8 AM it could compile: “Today’s schedule: 3 meetings (first one at 9 AM), 2 tasks due, and 5 unread important emails.” This briefing could be delivered via Slack DM or email. Implementation-wise, this could be a scheduled cron job that queries the user’s Calendar and Tasks for the next day or week, summarizes them (possibly using the LLM to highlight what’s important), and then sends out a formatted message. Initially, a simple summary without AI might suffice (just list events and tasks). Implementation Steps:
Capture Reminder Requests: Allow users to input reminders. In the web app, include a quick “Add reminder/to-do” interface. In Slack, the user could message the bot (e.g., “remind me to...”) or use a slash command. Use an LLM to parse natural language inputs into a structured task (e.g., task description and due date) when needed.
Create Task via API: Use the Google Tasks API to insert a new task for the user with relevant details (title, notes, due date/time). For simple date-based reminders, we could alternatively use Calendar events, but Tasks is suitable and keeps these to-dos separate from hard calendar events.
Scheduling the Notification: Decide how to trigger the reminder notification. The straightforward approach is for the backend to track due times (e.g., poll or use a scheduled job). For example, every minute a background job checks for any task due in the next minute and sends the Slack DM. This can be implemented with a lightweight scheduler (Cloud Scheduler or even a loop on the server) or using Slack’s ability to schedule messages in advance.
Slack DM Reminder: When it’s time, compose a Slack message to the user with the reminder text. Use the Slack Web API (chat.postMessage or chat.scheduleMessage) to send it to the user’s DM channel. We’ll need the user’s Slack ID and the bot token (see Slack Integration below) to do this. The message should be succinct and clear (possibly include the task title and due time).
Mark Complete (Optional): If we want to auto-cleanup, after sending a reminder we could mark the task as completed in Google Tasks via the API, or we might leave it for the user to check off. At minimum, we should not send duplicate reminders, so ensure each task is only reminded once (we could update a metadata field or our own log to indicate it was sent).
By plugging into Google Tasks, we avoid needing any external task management service – everything stays within the Google ecosystem. The user benefits by having a single source of truth for tasks, and Slack DMs ensure the reminders are seen in real time. For recurring reminders (like “every Monday 9am send report”), we could either use Slack’s recurring reminders or store it as a recurring task and handle it accordingly, but that can be an extension. The key is that AmayAI will make sure no important to-do is forgotten.
Slack DM Notifications (Replacing Calls & Texts)
In the original Martin system, the assistant could place phone calls or send SMS/WhatsApp messages to get your attention or relay information. In our company-focused clone, we will replace those channels with Slack direct messages. Slack is our team’s primary communication tool, so it’s both effective and appropriate to use for AmayAI’s alerts and interactions. This means any reminder, prompt, or urgent update from AmayAI will come as a DM from a Slack bot (AmayAI’s persona) rather than a text or call. It also means employees can interact with AmayAI by messaging the bot on Slack, just like they would message a human assistant. Using Slack for notifications has several benefits: it’s instant, it’s less intrusive than a phone call, and it keeps a written record. For example, if AmayAI needs to nudge a user about something (“You have an unread alert that looks like a bill – should I add a reminder?”), it can send a Slack message with that question. The user can then respond in Slack or click a button, and the assistant can act accordingly. Slack DMs will also be used for delivering reminders (“Don’t forget your 1 PM meeting”) and daily briefings as discussed. Essentially, Slack becomes AmayAI’s voice. From an implementation standpoint, we will create a Slack bot user for AmayAI inside the company’s Slack workspace. With the proper permissions, this bot can initiate DMs with any user in the workspace and post messages. All it takes is a single Slack OAuth token for the bot – no need for per-user Slack auth unless we want to receive messages (we’ll cover options in Slack Integration section). The heavy lifting of OAuth and identity mapping we’ve done for Google doesn’t conflict with Slack’s model at all; we can comfortably use both APIs side by side. How it works: Once the Slack app (bot) is set up and installed for the workspace, our backend will use Slack’s Web API to send messages. Each user is identified by a Slack user ID (like U12345) – AmayAI needs to know each user’s Slack ID to DM them. We can obtain that either by asking each user to authenticate Slack once (to link their Slack account, retrieving their user ID) or by using the Slack admin APIs to look up users by email (if the Slack profile emails match their Google email). For simplicity, we assume the latter: we can call Slack’s users.lookupByEmail method (or the newer users.identity with an admin token) to get a user’s Slack ID from their email address. Since all our users use their @cmacroofing.com email in Slack, this mapping should be reliable. Whenever AmayAI needs to notify someone (for a reminder, nudge, etc.), the backend will form the message text and call chat.postMessage with the Slack user ID as the target channel. Using a user’s Slack ID as the “channel” in a Slack API call will send a DM to that user from our bot. For example, our request might be: chat.postMessage with JSON body { "channel": "U0ABC1234", "text": "Heads-up: your next meeting starts in 10 minutes." }. Slack will deliver that as a direct message from AmayAI to the user. We can also include rich formatting or even interactive buttons in these messages (for future enhancements like “Complete task” buttons). AmayAI will also listen for user messages on Slack if we choose to support that. This means if a user DMs the AmayAI bot with a request (“schedule a meeting with Bob next week” or “what’s my day look like?”), we would receive that via a Slack events API and can respond accordingly. Supporting incoming messages requires adding a bot event subscription (and possibly a slash command for structured commands), and it will involve parsing the user’s message (again likely with the LLM) to figure out the intent. This is a stretch goal, but it aligns with Martin’s design of being reachable on any channel. Initially, our Slack integration can be one-directional (assistant -> user notifications), but it’s good to design with two-way in mind, as it greatly enhances usability. Implementation Steps:
Slack App Setup: Register a Slack app for AmayAI in the company Slack workspace. Grant it minimal scopes needed: at least chat:write to send messages and im:write to open IM channels (DMs) proactively. If we plan to use Slack’s reminder feature or need to set reminders, also add reminders:write (optional). Install the app to the workspace and obtain the Bot User OAuth Token (usually starts with xoxb-...). This token will be used by our backend to authenticate to Slack’s API.
Store Credentials Securely: Save the Slack bot token in a secure manner (e.g., as an environment secret or in a secure key vault). The backend code will load this token to authorize Slack API calls. Never hard-code it. (In production, Google Secret Manager or similar can be used to store secrets safely.)
User ID Mapping: Establish how to get each user’s Slack ID. The easiest method is to use the Slack Web API method users.lookupByEmail with an admin token, which requires an admin scope or token. Alternatively, perform a one-time OAuth for each user: when the user logs into AmayAI’s web app, also have them authorize Slack and record their Slack user ID. For now, assume we can map by email without bothering the user (since all users share the domain and Slack likely has their emails). We will need either a Slack token with the right permissions to do this lookup or we can maintain a manual mapping if trivial.
Sending Messages: Implement a utility in the backend to send Slack DMs. Using the bot token, call Slack API methods like chat.postMessage to send immediate messages. For scheduled notifications, consider using chat.scheduleMessage to schedule a DM for a specific time (Slack will then send it at that time without our server needing to wake up). For recurring notifications (like daily briefings), either schedule them each day via chat.scheduleMessage or use a server-side scheduler (e.g., a daily cron job that calls chat.postMessage each morning).
Testing and Fail-safes: Test sending a message to a known user ID to verify the bot can DM. Ensure to handle errors (e.g., if a user ID is wrong or the bot isn’t invited to a channel). Since the bot is in the workspace, it should be able to DM any user by default. Also, implement some logging for messages sent, so we have an audit trail.
With Slack notifications in place, users will get timely updates from AmayAI in a non-intrusive way. This approach leverages Slack’s reliability and avoids building a separate notification system. It effectively replaces SMS/text reminders with Slack DMs, aligning with company practice. In terms of user experience, after a while, interacting with AmayAI on Slack should feel as natural as chatting with a colleague – they can ask it for help or expect it to ping them when needed.
Proactive Nudges (AI-Driven Suggestions)
One of the powerful aspects of having an AI assistant embedded in your workflow is that it can proactively assist you without being asked. AmayAI will include a “proactive help” engine that observes patterns in your emails, calendar, and tasks and suggests helpful actions. Martin’s system does this too – for example, if it notices “You have an unread bill-pay alert”, it might ask if you want a reminder set for it. For our implementation, proactive nudges could cover scenarios relevant to our business context, such as:
Detecting that an important email from a client has gone unanswered for 3+ days, and prompting: “You haven’t responded to [Client]’s email about XYZ. Would you like me to draft a follow-up?”
Noticing back-to-back meetings on your calendar and suggesting to block out some focus time or prepare materials.
Spotting that a meeting is scheduled without a conference link or location and offering to add one.
Finding tasks that are overdue and nudging the user to update or reschedule them.
How it works: The proactive engine will run periodically (perhaps once a night or during off-peak hours) and use the LLM to analyze recent user activity for potential issues or opportunities. Concretely, we might have a nightly job that looks at the past 30 days of emails and calendar events, plus upcoming events, using lightweight queries: e.g., fetch emails that are still unread or not replied to, get calendar events for the next week. We then feed a summary of this data to the LLM with prompts to identify anything noteworthy: for example, “Among these, find any situations where something might need the user’s attention that they have not addressed.” The LLM can be instructed to output suggestions like “unanswered invoice from X” or “meeting tomorrow with no agenda.” This is essentially an AI-driven analysis of the user’s workflow patterns. Once the AI highlights potential items, AmayAI will generate suggestion cards for the user. In the web dashboard, there could be a section “Proactive Suggestions” listing things like:
“You have 2 unanswered client emails from last week. [View Emails] [Draft Replies]”
“Your project kickoff meeting with ABC Corp has no agenda. [Add Agenda]”
“It’s been 1 month since you last updated the CRM. Shall I schedule a reminder to do that?”
Each suggestion would give the user an option to act (one-click actions like drafting a reply, adding a reminder, or ignoring the suggestion). These could also be pushed to the user via Slack DM for immediate notice, especially if time-sensitive (“You have a meeting in an hour with no deck attached – want me to ping someone for it?”). Implementation Steps:
Periodic Analysis Job: Configure a scheduled job (e.g., a daily Cloud Run job or cron) that runs the proactive analysis. This job will use Google APIs to pull a slice of user data: for example, list of emails in the inbox or specific labels (like “inbox” or “unread”), and upcoming calendar events for the next few days.
LLM Prompting: Prepare a prompt for the LLM that provides metadata of these emails/events (we may not send full email bodies for privacy, maybe just subjects and dates or types) and asks the LLM to find any “actionable” items or patterns. This might include logic like: find any unread emails that seem important, any email threads where the last incoming email was >5 days ago and user hasn’t replied, any upcoming meetings missing details, etc. The LLM can identify such patterns and respond with suggestions. If using OpenAI, this data will leave Google’s cloud, so ensure no highly sensitive info is included or use anonymized text. If that’s a concern, using Google’s Gemini model via Vertex AI could be an alternative – it can be configured to respect data governance and PII rules, keeping analysis in-house.
Generate Suggestions: Parse the LLM’s output into structured suggestions. Each suggestion should have a description (“unanswered email from Alice about Contract”) and a recommended action (“Draft a reply” or “Set follow-up reminder”). We might classify suggestions by type (email-related, calendar-related, task-related).
Surface to User: Add these suggestions to the user’s dashboard UI under a “Proactive Nudges” section. For each, allow the user to take action or dismiss it. Additionally or alternatively, send a Slack DM summarizing the suggestions, especially if it’s something the user might want to address soon. For example: “I noticed 2 potential tasks for you: [details]. Check the AmayAI dashboard for quick actions.”
Learning and Tuning: As the user accepts or dismisses suggestions, the system can learn what types of help are useful. We can refine the LLM prompts or filtering criteria over time to reduce noise. In early versions, we might keep the scope narrow (e.g., only look for obviously important things like emails from VIP contacts).
The proactive help engine essentially turns AmayAI from a passive tool into a more agent-like assistant. It’s continuously looking out for the user’s interests, which can significantly improve productivity (like a smart executive assistant who anticipates needs). Because this involves scanning user data, we must implement it with respect for privacy and with the option for the user to turn it off if desired. But given it uses the same data the user already has access to, and it runs internally, it should be a welcome aid. Technically, this feature is an extension of the core pieces (email, calendar, LLM) with some pattern-recognition logic layered on top.
Google Workspace Integration (Gmail, Calendar, Tasks)
To achieve the above functionality, AmayAI will deeply integrate with Google Workspace services: primarily Gmail, Google Calendar, and Google Tasks. All user data and actions are handled through these Google APIs, which means we don’t need any external systems for email, scheduling, or task management – we piggyback on Google’s infrastructure. The key design decision here is to use a Google Cloud service account with domain-wide delegation to access user data centrally. Service Account & Domain-Wide Delegation: We will create a service account in Google Cloud that has domain-wide access to the company’s Google Workspace data (restricted to specific scopes). Domain-wide delegation allows our backend to impersonate any user in the domain when calling Google APIs, with admin-granted permission. In practice, this means our server can perform actions on behalf of alice@cmacroofing.com or bob@cmacroofing.com by using the service account’s credentials and specifying the target user. This approach eliminates the need for each user to individually OAuth-consent to Gmail/Calendar access; instead, the Google Workspace admin consents one-time for the whole domain for certain data scopes. As long as we include a “subject” (impersonated user email) in our API requests, Google knows to access that user’s data. For example, if the service account is set up properly, our code can do something like:
python
Copy
creds = service_account.Credentials.from_service_account_file("svc.json", 
    scopes=["https://www.googleapis.com/auth/gmail.modify"], 
    subject="alice@cmacroofing.com")
gmail_service = build("gmail", "v1", credentials=creds)
gmail_service.users().messages().list(userId="me", q="is:unread").execute()
In this snippet, by setting subject="alice@cmacroofing.com", the Gmail API call will fetch Alice’s unread emails. If we change the subject to Bob, the same credentials now operate on Bob’s mailbox. This is incredibly powerful: one service account key can access all mailboxes/calendars, but only one at a time and only for the scopes granted. It never has blanket access without impersonation, and it never uses the admin’s account or password – it’s all through delegated OAuth tokens. We will request delegation for Gmail, Calendar, and Tasks APIs. The exact OAuth scopes likely include: Gmail read/write (gmail.modify which covers reading and sending emails), Calendar read/write (calendar.events scope), and Tasks read/write (tasks scope). The domain admin (Cody) will whitelist these scopes for our service account’s client ID in the Google Workspace admin console. This setup is a one-time thing – once configured, our backend can impersonate any user in the domain to call those APIs without further user consent. Using the Google APIs: With delegation in place, AmayAI’s backend essentially acts like each user’s personal agent on Google. The major Google APIs we’ll use are:
Gmail API – for reading emails, searching threads, sending emails (replying), applying labels, and watching for new messages. We’ll use endpoints like messages.list, messages.get, messages.send, and Gmail push notifications.
Calendar API – for checking availability (FreeBusy query), creating and updating events, and reading events (for proactive checks or briefings). Endpoints include events.insert, events.list, and freeBusy.query.
Tasks API – for creating and managing to-do items and reminders. Endpoints include tasks.insert, tasks.list, etc., under the user’s default task list (or a designated list for AmayAI if we prefer).
People API (optional) – we might use the Google People API (or Directory API) to get information about contacts or coworkers, e.g., to fetch a user’s contacts when drafting an email, or to translate names to emails. This is not core, but it could be handy for things like ensuring we have correct email addresses or for later enhancements (like if the assistant is asked “who is John Doe?”, it could look up the company directory).
Google Drive API (optional) – not in scope for now, but if in the future AmayAI needs to fetch or insert attachments (like finding a file to attach to an email), we might integrate Drive. For now we will not request Drive scope (principle of least privilege).
All these API calls will be made by our backend server. Thanks to the service account impersonation, we’ll handle authentication transparently. The user will likely log into the AmayAI web app with Google OAuth as well (for front-end side authentication), but that is just to verify their identity and perhaps to get basic profile info; the heavy data operations will use the service account in the backend. Data Flow Example: To illustrate, consider the email triage flow for a user (say Alice). Alice logs into the AmayAI web app via Google Sign-In, so we know her email. We subscribe to Gmail push notifications for Alice’s mailbox using the service account (with subject Alice). When a new email comes in, Google sends a notification to our webhook. Our backend receives it and knows it’s for Alice’s inbox. We then initialize credentials with subject=Alice and call Gmail API to get the email. We process it and perhaps call the LLM. Then we might call Gmail API again (still as Alice) to apply a label or send a reply draft. All of these calls use the single service account key, just switching the “subject” each time for different users. This design scales to multiple users easily – the only limitation is we must always remember to specify the correct user’s email as the subject on each API call. If we forget, the API will return an error because the service account itself doesn’t have a mailbox or calendar. Advantages of this approach: It centralizes integration and is IT admin-friendly. We don’t have to worry about token storage per user or refreshing dozens of OAuth tokens – just one service account credential to manage. It’s also secure when configured correctly: the service account can only access the scopes granted. We will ensure to request the minimum scopes necessary (for example, we might use a Gmail scope that allows reading and sending but not full mailbox settings access). The admin can audit or revoke the service account’s access at any time from the admin console. And any API action we take can be logged for compliance (we can log which user we impersonated and what we did, to have an audit trail). Finally, using Google’s own APIs means we inherit a lot of power out-of-the-box: search in Gmail, event invites in Calendar, etc., come for free. We just orchestrate them. Google’s reliability and security (OAuth scopes, data in transit encryption, etc.) apply to all these interactions. In essence, we are building on top of Google Workspace as a platform.
AI Integration: OpenAI GPT-4 (or Google Gemini)
AmayAI’s “brain” for understanding language and generating smart outputs will be a Large Language Model. This is what enables features like summarizing emails, drafting replies, parsing instructions, and finding patterns. We have two primary options: OpenAI's GPT series or Google’s new Gemini model via Vertex AI. The choice can be left to implementation or even abstracted (developers could write a service with a pluggable LLM backend). Both have pros and cons:
OpenAI GPT-4/GPT-3.5: These models are state-of-the-art in language understanding and generation. GPT-4 in particular is known for high-quality, coherent outputs and is already used in similar products (Martin itself uses “GPT-4-class models” under the hood, and tools like Superhuman’s AI Reply use OpenAI). Using OpenAI’s API is straightforward: we send the model a prompt and get a completion. OpenAI also supports features like function calling, which could be useful (e.g. we can have the model extract structured data like dates or classification tags by defining a function schema). The downside is data governance – sending content to an external API (OpenAI’s servers) might raise privacy considerations, though OpenAI offers policies for data usage. Also, cost and rate limits must be considered, but for a corporate assistant with moderate volume, this should be manageable.
Google Gemini (via Vertex AI): Google’s own family of next-gen models (Gemini) are accessible through Google Cloud’s Vertex AI platform. By the time of this project, Gemini 2.x may be available. Using Gemini could keep more data within the Google Cloud environment, which might be preferable for privacy – especially since our data is from Google Workspace, processing it with Google’s AI might ensure it stays under Google’s compliance umbrella. Vertex AI also allows setting data governance policies (like not logging prompts that contain PII). However, at present, OpenAI’s models are often regarded as more capable/mature in many language tasks. Gemini is improving rapidly, but if we need best-in-class quality now, GPT-4 might be the pick. We could even implement a strategy: start with OpenAI (for proven results) and plan to shift to Gemini in the future when it’s on par or if data residency becomes a concern.
LLM Usage in AmayAI: We will use the LLM for several distinct tasks:
Summarization: Summarize email threads or long emails into concise bullets or a sentence. (Used in inbox triage and daily briefings.)
Draft Generation: Generate possible email or message replies given context. (Inbox drafting, possibly Slack message drafting for suggestions.)
Classification/Prioritization: Determine the nature or urgency of content. For instance, classify an email as urgent vs low-priority, or identify if an email is a request, an FYI, a calendar invite, etc.
Intent Parsing: Understand user commands or requests given in natural language (through Slack or voice/text inputs). For example, parse “Remind me to call John next Monday” into structured data (task: call John, date: next Monday).
Pattern Recognition: Analyze user’s data for proactive suggestions, e.g., identify an “unanswered invoice email” or “meeting with no agenda” as we described in nudges.
Each of these use cases may involve slightly different prompting techniques:
We might fine-tune or write specialized prompts. E.g., for email triage: “You are an assistant. Summarize the email thread below in one sentence, and draft three brief reply options.” including the thread text.
For scheduling, we might use the model’s reasoning to extract possible meeting times from text, or even to interpret a vague request like “sometime in early next week”.
For parsing tasks/reminders, a prompt could be like: “Extract the action, date, and time from this request: ‘Remind me to submit the report on Nov 5th at 9AM’.”
For proactive scanning, we might feed a list of recent email subjects and ask: “Do any of these look like something the user might need to follow up on?”
The developers should leverage the chosen LLM’s strengths. If using OpenAI, GPT-4 is recommended for its better understanding, especially for drafting professional emails or handling tricky language in scheduling. If budget is a concern, GPT-3.5 Turbo can handle many tasks reasonably well (perhaps summarization and straightforward replies). If using Google’s Vertex AI (Gemini), they may have specific models or tuning options for enterprise use – for instance, a model optimized for email/chat might be available. Integration Details:
OpenAI API: We’ll obtain an API key and use OpenAI’s REST endpoint (or their Python/Node SDK) to send prompts. We must be mindful of token limits (ensure prompts aren’t excessively long – possibly truncate long email threads or use conversation history strategically). Also, incorporate error handling and fallbacks (if the API is down or returns an error, the system should handle gracefully, maybe retry or default to not drafting).
Vertex AI API: If we go this route, we’d use Google Cloud’s SDK to call the Vertex AI models. This requires enabling the API in our GCP project and having the service account granted permission to use it. The calls would similarly send text and receive a completion. Latency and performance should be tested for whichever model we use.
We do not need to hard-commit to one model in the design. We can abstract the LLM calls behind a service interface so that switching from OpenAI to Gemini or vice versa is not too difficult. Initially, using OpenAI might get us results faster (given known examples and documentation), but we’ll keep an eye on Gemini’s capabilities. Security-wise, whichever LLM we use, we should avoid sending extremely sensitive information in prompts if possible. Since this is an internal tool, most data is internal anyway, but for example, if an email contains personal identifiable info or confidential data, that will be going to the LLM provider. If that’s a problem, one could choose Gemini (keeping data in Google Cloud, assuming Google is a trusted environment for this company) or filter out certain content from prompts. At least, we should document this aspect so the company is aware and can make an informed decision or add an agreement with OpenAI if needed. In summary, the LLM is a crucial component that gives AmayAI its “smarts.” We will use it for language understanding and generation tasks throughout the application. The development team has flexibility in choosing the model, but must integrate its API carefully and ensure responses are handled appropriately (always have a reasonable default if the LLM produces something unusable).
Slack Integration (Notifications & Commands)
Integrating Slack is essential for AmayAI to communicate with users in real time. We’ve outlined how Slack DMs will be used in the features above; here we provide more detail on setting up and using the Slack API as developers. Slack Bot Setup: We need a Slack app (bot) with the ability to send direct messages to users. Cody or an admin will create this Slack app in the company’s Slack workspace (via api.slack.com). The app should be given the following OAuth scopes:
chat:write – allows the bot to post messages in channels and DMs.
im:write – allows opening a DM channel with a user (so the bot can initiate a conversation if it hasn’t already).
reminders:write – (optional) if we want to use Slack’s built-in reminders (not mandatory, as we can handle reminders ourselves, but available).
We do not need broad scopes like reading channel history or user info for our current requirements, which keeps the app limited in access (good for security). Once scopes are set, the app is installed to the workspace. During installation, Slack will provide an OAuth access token for the bot (starting with xoxb-...). We’ll capture that token for use in our backend. We should also note the Signing Secret Slack provides, in case we set up any interactive components or event subscriptions (used to verify Slack’s requests).
Messaging Users: To send a DM, we need the Slack user’s ID (a string like UXXXX12345). As discussed, we can map users by email or ask them to connect Slack. A quick approach is to use Slack Web API method users.lookupByEmail (which requires the bot token plus the users:read.email scope or an admin token). Alternatively, Slack’s newer apps don’t easily expose users.lookupByEmail to bots without a User token, so another trick is: have a small “Sign in with Slack” button in AmayAI for users to click, which does a Slack OAuth flow granting identity.basic just to get their user ID. Another approach is Slack’s SCIM API or company directory if available, but that might be overkill. For now, plan on a one-time mapping: either manual input or using email matching. The development team can decide which method is simpler given the environment (e.g., if only a few users, mapping by hand is fine; if many, an automated lookup is better). Once we have a user’s Slack ID, sending a message is done via HTTP POST to Slack’s endpoint chat.postMessage with JSON payload containing the channel (user ID) and message text (and token in header). We can use Slack’s official SDK (for Node or Python) to simplify this call. For example, using Python pseudocode:
python
Copy
slack_client = SlackClient(bot_oauth_token)
slack_client.chat_postMessage(channel=user_id, text="Your meeting starts in 10 minutes.")
This will drop the message into that user’s DM with the bot. If the bot has never spoken to the user before, Slack will automatically create a new DM channel (thanks to im:write scope) so the user sees it. We should also handle the case of scheduling messages:
For one-off future notifications, Slack provides chat.scheduleMessage where we provide a Unix timestamp for the future send time. This is very handy for reminders: when we create a reminder task due at 5pm, we can immediately schedule a Slack message for 5pm. Slack will then deliver it at that time, even if our app is not running or is busy – no need for us to manage a timer. The limitation is these are one-shot; for repeating reminders, we’d have to schedule each occurrence separately (or use Slack’s recurring reminders).
For recurring notifications (like daily briefing), Slack’s reminders.add could be used (this sends via Slackbot, not our bot, and the reminders show up slightly differently). Alternatively, simply use an external scheduler (like a daily cron job in our backend) to send the message every day. The blueprint recommendation is that for quick nudges, using Slack’s scheduling is simplest, and for anything more complex, handle it on our side. We can follow that: use chat.scheduleMessage liberally for simplicity.
Receiving Messages (Optional): If we want AmayAI to respond to Slack messages from users, we will set up a Slack Events subscription on the app. This requires hosting an endpoint (which our web app backend can provide) and verifying it with Slack. We’d subscribe to message events (specifically direct message events to the bot). Whenever a user sends something to the bot, Slack will POST the event to our endpoint. Our backend then needs to parse the text and decide what to do (likely feed it to the LLM or interpret commands). For example, if user DMs “schedule meeting with Bob tomorrow at 2”, our backend could parse that and trigger the scheduling workflow. Implementing this would involve adding event.subscriptions scope and a bit more code, but it’s not strictly needed for initial functionality if we focus on output notifications. However, since the assistant is more useful if it can be summoned on Slack, it’s worth keeping in mind as a near-term enhancement. Slack App Configuration Summary:
App Name: e.g. “AmayAI Assistant”.
Bot Username: e.g. “AmayAI” (so DMs come from “AmayAI”).
Scopes: chat:write, im:write (+ maybe commands if using slash commands, reminders:write optional).
Redirect URLs: If using OAuth for user identity, set the redirect URL to our web app’s callback.
Event Subscriptions: If enabling, subscribe to message.im events (direct messages).
Interaction Settings: If we use interactive buttons in Slack messages, we’ll need to set an endpoint to receive those actions as well.
Finally, we must ensure to treat Slack credentials securely and follow best practices:
Keep the bot token secret (it grants the power to post as the bot in our workspace).
Do not hard-code channel IDs or user IDs; always look them up or configure them.
Log Slack errors for troubleshooting (e.g., if a message fails because user has left the company, we’d know why it wasn’t delivered).
Respect rate limits: Slack allows a certain number of messages per second; our use (a few per user per day perhaps) is low-volume, but be mindful in code (the Slack SDKs handle rate-limits internally typically).
With Slack integration properly set, AmayAI will effectively have a real-time communication line to each user. This dramatically increases its usefulness (no need for the user to constantly check a separate app; they get notified on Slack about whatever is important). It also means we can gradually add interactive capabilities on Slack, turning it into another interface for the assistant alongside the web app.
Web App Interface (Dashboard)
AmayAI will initially be delivered as a web application (with plans for an iOS app later). The web interface is where users can log in, view what the assistant has done or suggested, and interact with those items. We should design it as a dashboard for the user’s day, integrating the various features: Key elements to include on the web UI:
Inbox Triage Dashboard: A section showing new emails or threads that have been processed by AmayAI. For each thread, display the AI-generated summary and any draft replies. Let the user click to open the full email (maybe via a link to Gmail or an in-app viewer), and have buttons like “Send this draft” or “Ignore”. This makes it easy to blast through emails by just approving drafts or reading summaries.
Tasks/Reminders List: A to-do list view showing the user’s current tasks and reminders (fetched from Google Tasks). This could be integrated with the email view (e.g., a button to create a task from an email) or standalone. Allow adding a new task/reminder from here as well. Indicate which ones were added by AmayAI proactively.
Calendar Overview: A mini calendar or list of today’s events, possibly with any scheduling actions AmayAI took. (E.g., “Meeting with Client X – scheduled by AmayAI”). This reminds users of their schedule and shows that AmayAI is keeping their calendar organized.
Proactive Suggestions: As described, a section for “Would you like me to…?” suggestions that the assistant has generated. Each suggestion might have an action button (like “Yes, do it” which could trigger the assistant to execute the suggestion).
Settings/Preferences: Some interface for the user to adjust preferences. Early on, this might just be minimal (maybe a toggle for “send me daily briefings” or “allow proactive suggestions”). Also possibly a “Connect Slack” button if we do user-specific Slack OAuth. Additionally, an option to disconnect or log out, etc.
Because it’s internal and for a controlled set of users, we don’t need an overly polished UI at first, but it should be clean and not confusing. Using a modern web framework will help build this quickly. The developers are free to choose the stack – for example, a React-based single-page application would work well. The blueprint suggestion was Next.js or Remix (React frameworks with good support for server-side rendering and integrating with OAuth), but it’s ultimately the team’s choice. What is important is implementing Google OAuth login on the web app: users should sign in with their Google Workspace credentials (we can restrict OAuth to the company domain). This gives us their identity securely and can also provide a Google ID token if needed for some API calls (though mostly we use the service account for data, not the user’s token). Steps for the web app:
Authentication: Use Google’s OAuth 2.0 to sign users in. Register the app in Google’s API console to get a Client ID for OAuth (since it’s internal, this might be a “internal app” in Google’s terms). Request at least the profile and email scopes to get the user’s email. We might not need to request Gmail/Calendar scopes here because the service account covers data access – the OAuth is just for authentication (and maybe verifying they belong to the domain). Once authenticated, establish a session (could be a secure cookie or token) so the backend knows which user’s data to show (e.g., user ID or email in session).
Impersonation linkage: When the backend receives a request from a logged-in user, it knows the user’s email (from session or token). It will then use the service account credentials with that email as subject to fetch data. For instance, when the front-end calls an endpoint to get “triage results”, the backend will impersonate that user to query Gmail or our database for stored summaries.
Real-time updates: Ideally, the dashboard updates as new things happen (new email arrives, a reminder triggers, etc.). We can implement a simple WebSocket or use a service like Firebase/Firestore if we had one. A lightweight approach is for the backend to push notifications via WebSocket to the front-end when, say, a new triaged email is ready, or a suggestion was generated. This avoids the user having to refresh. However, initially it could be acceptable to refresh the page or have the front-end poll every few minutes. Given the context, using a WebSocket or Server-Sent Events could be a nice touch (the blueprint mentioned possibly using Pub/Sub and WebSockets for real-time updates).
No Mobile Yet: We explicitly note that a native iOS app will be built later, so we do not need to accommodate mobile-specific functionalities beyond making sure the web app is responsive for mobile browsers. However, we should design our backend with an API structure that could be reused by a mobile app. For example, the backend might have REST endpoints or GraphQL that the web app uses to fetch data; an iOS app could use the same endpoints. So, it’s wise to keep the web front-end somewhat decoupled from the logic (maybe the front-end calls a REST API which our backend service provides). Replit devs can certainly just build a combined app (depending on language, maybe a Next.js that serves API routes and front-end together). The main point is: don’t lock into something that makes a future mobile app integration difficult. Using standard protocols and having a clear separation of front-end and back-end logic will help.
Google Workspace Add-on (Future): As an aside, Google offers the ability to create Workspace Add-ons that appear inside Gmail or Calendar UI. This could be a way later to integrate AmayAI directly into Gmail’s sidebar for users. It’s not needed now, but we mention it because we should not build anything that precludes that path. If our backend is accessible via HTTPS and we have the right integration points, we could reuse a lot of the code in an add-on. For now, we focus on the standalone web app.
In terms of framework/language, the developers have freedom. They can use a Python Flask/Django backend with a React front-end, a Node/Express backend with React or even a full-stack Next.js that handles both server and client. We do not enforce any particular framework here – whatever allows rapid development and easy maintenance is fine. The only requirement is that it fulfills the integration points (Google OAuth, calling Google APIs, Slack API, and LLM API). To summarize, the web app is the control center for the user’s interactions with AmayAI. It should be designed to clearly present AI-generated assistance (so the user trusts and benefits from it without confusion), and to allow the user to give feedback or instructions easily. A clean, uncluttered UI with logical sections (Email, Calendar, Tasks, Suggestions) will likely work well. The dev team should leverage existing UI components or libraries for things like a calendar view or list management to speed up development.
Security and Best Practices
Building an assistant that has access to communication and schedule data means we must take security seriously. Here are key security considerations and best practices for AmayAI:
Least Privilege OAuth Scopes: When configuring Google Workspace API access, only request the scopes absolutely necessary for functionality. For example, use Gmail scopes that allow reading and sending email, but not deleting or settings if not needed. Avoid blanket scopes like https://mail.google.com/ (full access to Gmail) if a narrower scope like Gmail readonly plus Gmail send would suffice. The same goes for Calendar (perhaps only events scope) and Tasks. This limits the damage if credentials were misused and is better for compliance.
Secure Storage of Credentials: All sensitive keys and credentials (service account JSON key, Slack bot token, OpenAI API key, etc.) should be stored in a secure manner. On Replit, this means using the Secrets management (so they aren’t exposed in code). In production on GCP, one would use Secret Manager. Never commit these secrets to the repository.
Encryption in Transit: All API calls to Google, Slack, OpenAI, etc., are over HTTPS, which is good. The web app should enforce HTTPS as well (especially if deployed under a custom domain, ensure SSL).
Authentication & Session Security: Use secure cookies or tokens for the web app session. If using JWTs, sign them strongly. Ensure that only authenticated users (from the domain) can access the app – possibly restrict Google OAuth to the company’s domain accounts. This prevents outsiders from even attempting to use the assistant.
Audit Logging: It’s a good idea to keep a log of significant actions the assistant takes on behalf of users. For instance, log every time an email is auto-sent or a meeting is scheduled, including who it was for and when. This can be just an internal log or even surfaced to the user (“Activity log”) for transparency. On the admin side, Google’s audit logs can show API calls made with the service account, and Slack’s admin panel can show messages the bot sends. We should encourage reviewing those logs to ensure nothing fishy is happening. Since the service account can impersonate anyone, if its credentials were stolen, it would be serious – so monitoring its usage is critical.
Impersonation Control: Only our backend servers should possess the service account key and be able to impersonate users. Never send the service key to the front-end or to users. Also, build safeguards in code – e.g., only allow the service account to impersonate users within @cmacroofing.com domain, and only in response to authenticated user actions or system triggers. This prevents accidental misuse like impersonating an admin when not appropriate.
Rotating Keys: Consider periodically rotating the service account key and Slack token if feasible. Slack tokens can be set to automatically rotate (with a 12-hour window, requiring refresh logic), but that might be unnecessary for our internal tool scale. Still, if Slack offers short-lived tokens, we could implement refresh.
Compliance with Company Policies: Since this is internal, ensure that using an external LLM (OpenAI) is approved by the company. If not, stick to Google’s Vertex AI which might be covered under existing Google Workspace agreements. Also, ensure users know that an AI is reading their emails – this might be obvious, but it’s good to communicate clearly so they aren’t surprised. Maybe include a one-time “consent” or information screen when they first use AmayAI.
Fail-safes: If for some reason the service account is revoked or an API quota is exceeded, AmayAI should handle it gracefully. For example, if Gmail API calls start failing, perhaps pause certain automations and alert an admin (or Cody). The user should never have a completely broken interface; degrade gracefully by maybe showing a message “Unable to fetch new data at the moment” if something’s wrong.
Testing in Sandbox: When building, test carefully with a limited scope before rolling out widely. Perhaps use a smaller subset of users or a separate Google Workspace sandbox domain to ensure everything works and is safe. The domain-wide delegation should first be tried with just one or two test accounts (impersonating yourself, etc.) to confirm that we’re not overstepping any boundaries.
By following these practices, we ensure that AmayAI remains a trustworthy tool inside the company. The power we’ve given it (read/write across mailboxes, calendars, etc.) is substantial, but with that power comes responsibility to secure it. We have essentially one “key to the kingdom” (the service account key) – protecting that is paramount.
Cody's Section – Setup Checklist for Infrastructure
Before development can begin in earnest, there are several setup and configuration tasks that Cody (the client) needs to complete or provide. These ensure that the Replit developers have the necessary access and credentials to integrate all the services:
Google Cloud Project & Service Account: Create (or designate) a Google Cloud project under the company’s account to be used for AmayAI. In this project, create a Service Account that will be used by AmayAI for Google Workspace access. Enable Domain-Wide Delegation for this service account:
After creating the service account, generate a new JSON key for it (this will be given to the developers).
In the Google Workspace Admin Console, go to Security → API Controls → Domain-wide Delegation. Add a new delegation entry for the service account’s Client ID and grant it the scopes it will need. Specifically, include:
Gmail API scopes (e.g. https://www.googleapis.com/auth/gmail.readonly, .../auth/gmail.send, or use .../auth/gmail.modify for full mail access).
Google Calendar API scope (https://www.googleapis.com/auth/calendar for read/write).
Google Tasks API scope (https://www.googleapis.com/auth/tasks).
(Optional) Any other scopes if needed (e.g. if using People API for contacts, include .../auth/contacts.readonly).
Enable the APIs: In the Google Cloud project, ensure the Gmail API, Calendar API, and Tasks API are enabled (via APIs & Services dashboard). This is required for the service account to actually use those APIs.
Provide the service account JSON key file to the development team securely (e.g., via a secure sharing mechanism, not email). This key is what the backend will use to authenticate. It effectively grants the necessary access, so treat it like a password.
(If not already obvious, Cody must have super-admin rights on the Google Workspace domain to perform these steps.)
Slack App Creation: Set up a Slack App in the company’s Slack workspace for AmayAI:
Go to Slack API site (api.slack.com/apps) and create a new app (give it a name like “AmayAI” and tie it to the workspace).
Under OAuth & Permissions, add the following bot token scopes: chat:write and im:write. Also add reminders:write if you plan to use Slack’s reminder features. (No user scopes are needed unless doing a user OAuth flow.)
Install the app to the workspace (you might need to be a Slack admin to do this). Upon installing, you will receive a Bot User OAuth Token.
Copy the Bot OAuth Token (starts with xoxb-) and provide it securely to the developers. Also copy the Signing Secret from the Basic Information page (needed if the devs set up Slack event subscriptions or slash commands).
In the Slack app settings, if you know you want to support incoming commands, you can set up an Slash Command (e.g., /amayai) and/or enable Event Subscriptions (subscribe to bot DM messages). If not sure, this can be done later by the devs, but having the app in place with correct scopes from the start is important.
OpenAI API Key (or Google Vertex AI Access): Decide which LLM service will be used initially and ensure access:
For OpenAI: Create an account at OpenAI and generate an API key (from the OpenAI dashboard). If the company already has an OpenAI API subscription or keys, you can use that. The API key should be for a paid tier if using GPT-4 (as GPT-4 is usually not available on the free tier). Provide this secret API key to the development team (again, via a secure channel).
Make sure to enable billing for OpenAI usage, as needed, so that the API calls won’t hit a hard cap.
For Google Gemini/Vertex AI (if opting for Google’s LLM): Ensure the Google Cloud project has the Vertex AI API enabled. You may need to request access if it’s in preview or set up billing on the GCP project for Vertex AI usage. Also, ensure the service account has permissions to use Vertex AI (like the AI Platform User role). The devs will need either a service account JSON (they can use the same one if properly permissioned) or another method to authenticate to Vertex AI. Clarify which route you want to go (OpenAI vs Google) so the devs know which API to integrate.
If undecided, you can provide both (OpenAI key and Google project access) so developers can start with one and have fallback to test the other.
Assistant Email Address (for Scheduling): Create a dedicated user or alias in Google Workspace for the assistant’s email (e.g., amayai@cmacroofing.com):
The simplest is to create a full user account (licensed user) named “AmayAI” with that email. This mailbox will be used to send scheduling emails and to receive any direct emails to the assistant.
Alternatively, you could create an email alias on an existing account, but a separate user is cleaner. If it’s an alias, ensure the service account can access that mailbox via delegation (if alias is on an admin’s account, perhaps not ideal).
Once created, share the credentials of this account with the devs if they need to access it directly for testing (or they can access its mail via the service account anyway). At minimum, inform the devs of the chosen email address, so they know to programmatically watch that inbox for scheduling requests.
If you prefer not to create a new user, we can have the service account impersonate the requesting user for sending scheduling emails (so the user themselves sends the proposal). This is a design choice. But creating an “assistant identity” might be nicer for clarity. Coordinate with the devs on which approach they will implement.
Environment for Development: Provide the Replit developers with any necessary access or environment setup on Replit:
They will need a way to securely store environment variables (Replit has a Secrets manager). Make sure they know the values (service account JSON, API keys, tokens) or have injected them.
If the development is happening on Replit, consider the implications of connecting to Gmail/Slack from that environment. Replit should allow outgoing API calls, but ensure no firewall or Google security setting is blocking it (sometimes new login attempts from unusual locations might trigger a security check – using service account should bypass interactive login though).
Possibly create some test user accounts for them on the domain (or be ready to test with your account) so they can simulate a real scenario. If providing a test account, give them credentials or at least the email and set up delegation for it too (but domain-wide handles all users already).
Miscellaneous Settings:
Company Working Hours/Timezone: Communicate any default working hours or timezone that should be considered for scheduling logic. (The devs can default to something but if the company has specific hours or multiple time zones, that’s good to note.)
User Preferences Defaults: If there are any company-wide preferences (like “don’t schedule meetings on Fridays after 3 PM” or similar) that you know of, let the developers know so they can include such rules or make them configurable.
Slack Workspace Details: Ensure the Slack workspace allows custom apps (most do unless restricted). Also, decide which channels (if any) the bot might post to besides DMs (perhaps none for now). If you want the bot to potentially post to group channels (like a team reminder), it would need to be invited to those channels. For now, plan is only DMs.
Completing the above setup tasks will equip the development team with the infrastructure and credentials needed to start building AmayAI. Once these are in place, the developers can proceed with writing the code to integrate Gmail, Calendar, Tasks, Slack, and the LLM, according to the specifications in this document. Each item is critical: missing any (like