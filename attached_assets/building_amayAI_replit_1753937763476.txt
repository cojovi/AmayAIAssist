Building AmayAI: AI Personal Assistant for Google Workspace
Purpose and Target Use Case
AmayAI is an AI-powered personal assistant web app designed to help employees at cmacroofing.com manage routine tasks and communications. Inspired by the capabilities of Martin (a Y Combinator-backed ‚ÄúJarvis-style‚Äù AI assistant), AmayAI‚Äôs purpose is to offload ‚Äúgrunt work‚Äù so users can focus on higher-value activities. It will handle things like triaging email, scheduling meetings, setting reminders, and drafting communications on behalf of users, learning their preferences over time to become more helpful. The target use case is busy professionals in the company‚Äôs Google Workspace domain who receive lots of emails, juggle meetings, and have many to-dos ‚Äì AmayAI will act as a 24/7 digital secretary to make their workday more efficient. Unlike Martin which interacts via phone calls or SMS, AmayAI will integrate with the company‚Äôs existing tools (Google Workspace and Slack). It will work fully within Google Workspace (Gmail, Calendar, Tasks) using corporate accounts and deliver notifications via Slack direct messages instead of texts or calls. This ensures AmayAI fits naturally into the company‚Äôs workflows ‚Äì for example, reminding users of tasks or meetings by pinging them on Slack, a channel they already use daily. In summary, AmayAI aims to provide Martin-like productivity benefits in a customized, secure way for the cmacroofing.com team.
Core Features and Capabilities
AmayAI‚Äôs functionality can be broken down into several core features. Each feature mirrors a capability of the Martin assistant and is implemented through Google Workspace integrations plus an LLM (Large Language Model) layer:
Inbox Triage & Drafting
This is one of AmayAI‚Äôs most valuable functions: helping users manage email overload. The assistant will monitor the user‚Äôs Gmail inbox and triage incoming messages ‚Äì for example, by applying labels or moving messages to folders, summarizing long email threads, and even drafting reply emails that the user can quickly approve and send. This is similar to how Martin handles email: it labels and sorts messages, generates a brief summary of threads, and writes suggested replies for the user. The goal is that when a user opens their inbox or AmayAI dashboard, they see a prioritized, summarized view of new emails with quick-action options (like ‚ÄúSend draft reply‚Äù or ‚ÄúSnooze‚Äù). How it works: Behind the scenes, AmayAI uses the Gmail API to read new messages and an AI model to analyze them. We will enable Gmail push notifications so the backend gets alerted whenever a new email arrives. When an email comes in, AmayAI‚Äôs backend will fetch the message via the Gmail API, then call an LLM (such as OpenAI GPT-4) to analyze its content. The LLM will be prompted to do things like: determine the email‚Äôs urgency, suggest an appropriate label or folder, produce a one-sentence summary, and draft a few possible replies the user might want to send. For example, if an email is a meeting request, the summary might be ‚ÄúClient X is asking to schedule a project call,‚Äù and the drafts might include polite responses. The assistant can then apply a label in Gmail (e.g. ‚ÄúNeeds Action‚Äù or ‚ÄúAwaiting Reply‚Äù) and store the AI-generated summary and replies. These results are surfaced in the web UI for the user to review ‚Äì the user might click one of the draft replies to send it, or edit it first. By leveraging a GPT-4-class model for this NLP-heavy task, we follow a proven approach (email tools like Superhuman have a similar ‚ÄúAI reply‚Äù feature built on OpenAI models). Implementation Steps:
Gmail Webhooks: Set up Gmail API push notifications using users.watch so that AmayAI is notified of new emails in real time. This avoids constant polling and ensures timely triage.
Email Fetch & Analysis: When notified of a new message, call Gmail‚Äôs API (messages.get) to retrieve the email content (and possibly thread history). Extract metadata like sender, thread length, existing labels, etc.
LLM Processing: Send a prompt to the LLM (OpenAI GPT or Google Gemini) with the email content and specific instructions. For example: ‚ÄúSummarize this email thread in one sentence, classify its importance (urgent or not), suggest a label or folder, and draft three brief reply options in the user‚Äôs tone.‚Äù The LLM‚Äôs response will contain the summary and draft replies.
Apply Triage Actions: Use Gmail API to apply any label or mark (if we decide on auto-labeling, e.g. mark as ‚Äútriaged‚Äù or move to a folder). Save the AI-generated summary and replies to our database or directly attach them in the UI for the user.
User Approval: In the AmayAI web interface, display the summary and draft responses for each new email. The user can choose to send a draft (in which case the backend will call Gmail API to send it) or modify it. Unused drafts can be discarded. The idea is the user spends seconds to handle an email that would otherwise take minutes to read and respond.
By automating email triage and reply drafting, AmayAI helps users reach ‚Äúinbox zero‚Äù faster. It‚Äôs important to let the user be the final decision-maker on sending AI-composed emails (at least initially) to maintain quality and trust. Over time, if confidence grows, some low-risk emails could even be auto-sent. All the heavy lifting here ‚Äì classification, summarization, generation ‚Äì is done by the LLM, while all email reading/sending uses the Gmail API with the user‚Äôs account (via impersonation).
Calendar Scheduling
AmayAI will serve as a smart scheduling assistant to eliminate the back-and-forth of finding meeting times. In practice, this means if someone needs to schedule a meeting, the user can loop AmayAI into the conversation and it will handle proposing times and creating the calendar event. Martin accomplishes this by having users CC an email address (e.g. martin@domain.com) on scheduling emails; the assistant then replies to the thread with available times and schedules the meeting on everyone‚Äôs calendars. We will do the same with AmayAI. For example, if a cmacroofing.com employee is emailing a client to set up a call, they can CC amayai@cmacroofing.com on the email. AmayAI (monitoring that inbox) will recognize the scheduling request, find open slots on the employee‚Äôs Google Calendar, and reply-all with a proposed time. Once the time is confirmed, AmayAI will create a Calendar event for all participants. It juggles conflicts and time zones automatically by leveraging Google Calendar‚Äôs data. How it works: AmayAI‚Äôs backend will utilize the Google Calendar API extensively for this feature. The workflow looks like this: When AmayAI is included in an email thread about scheduling, it will parse the email text to understand the meeting request (who the attendees are, any mentioned times or constraints). We can use an LLM to extract intent and timing from the email conversation (e.g. ‚ÄúClient asks for a meeting next week, 30 minutes‚Äù). Next, AmayAI will query everyone‚Äôs Google Calendar availability using the freeBusy.query endpoint ‚Äì this tells us what time slots are free for the user and optionally for other internal participants (for external attendees, we may only know what times the user is free and propose those). The assistant then chooses an optimal slot (the logic can be simple: earliest mutually free slot, within business hours, etc.) and creates a calendar event via the Calendar API. The event will include all attendees‚Äô emails and details from the context (title, location or video call link if needed). AmayAI then sends an email reply to the thread confirming the scheduled meeting time and attaches the calendar invite. This email can come from the assistant‚Äôs own address (e.g. amayai@cmacroofing.com) or impersonate the user‚Äôs address ‚Äì but using a dedicated assistant address is clearer to participants. Once done, the event appears on the user‚Äôs Google Calendar (and invites are sent to others automatically by Google Calendar). Implementation Steps:
Trigger Detection: Provide an email address for AmayAI (such as amayai@cmacroofing.com) and set it up as a user or alias in Google Workspace. Monitor this mailbox (via Gmail API) for incoming threads. When an email arrives that includes this address (CC/BCC), assume it‚Äôs a scheduling request and fetch the thread.
LLM Parsing (Optional): Use an LLM to analyze the email thread for scheduling details ‚Äì e.g., to find phrases like ‚Äúnext week‚Äù or ‚ÄúMonday afternoon‚Äù and to identify all participants. This helps interpret any human preferences stated in the emails. (If the request is straightforward or formatted, this step can be simple or rule-based.)
Availability Lookup: Call the Google Calendar API‚Äôs FreeBusy query to get open time slots for the involved internal users (at least for the main user on whose behalf we‚Äôre scheduling). The service account can also check coworkers‚Äô calendars if needed (provided appropriate access) to propose times when all internal parties are free.
Propose Times via Email: Generate a list of one or two optimal meeting slots (e.g. ‚ÄúHow about Tuesday at 3 PM or Wednesday at 10 AM?‚Äù). This text can be crafted by the LLM or by a template. Send an email reply in the thread from the assistant (AmayAI‚Äôs address) with the proposed times.
Book the Meeting: Once the other party agrees on a slot (they might reply or just accept one of the proposed invites), AmayAI creates the event on the user‚Äôs Google Calendar using the Calendar API. It sets the user as the event organizer (or the assistant user, depending on design) and adds all attendees. The Calendar API will automatically email invitations to attendees. AmayAI can then send a final confirmation email like ‚ÄúMeeting confirmed for Tuesday at 3 PM, invite sent.‚Äù
Conflict Handling: If none of the proposed times work (or if the user instructs AmayAI via Slack/UI to schedule a meeting with someone), the system may iterate: it could propose new times or use the LLM to negotiate a time. However, for MVP, it‚Äôs sufficient to propose a couple of times and let the humans finalize.
This scheduling feature saves users from tedious coordination. Essentially, we turn email threads + Calendar API into a scheduling engine ‚Äì ‚Äúcc to schedule‚Äù is implemented by combining natural language understanding (to read the request) and programmatic calendar management (to find free times and book events). The heavy logic (finding free slots) is handled by Google Calendar, and the assistant just orchestrates the communication.
Reminders, To-Dos, and Briefings
AmayAI will help users keep track of their tasks and deadlines through integrated reminders and to-do management. Users should be able to quickly create a reminder or task by telling AmayAI (for example, typing in Slack ‚Äúremind me to call the supplier tomorrow at 9am‚Äù). The assistant will record this in the user‚Äôs Google Tasks list (or Calendar, as a dated reminder) and then send a Slack DM at the appropriate time to remind the user. In addition, AmayAI can send daily or weekly ‚Äúbriefings‚Äù that summarize upcoming events or tasks ‚Äì similar to Martin‚Äôs daily briefing emails, but delivered via Slack or email based on preference. Under the hood, we will utilize Google Tasks API for to-do items and reminders, since Tasks is the built-in task system for Google Workspace. Every user in Google Workspace has their own Tasks lists, and AmayAI can create entries there for any reminders or tasks the user sets. By using Google Tasks, the reminders will also be visible to the user in their Google ecosystem (e.g., in Gmail sidebar or Google Calendar if they show tasks). For time-based reminders, AmayAI will keep track of the due time and then proactively notify the user when it‚Äôs time. How it works: There are two main ways reminders get into the system: user-driven and proactive. User-driven reminders are explicit requests (voice or text commands like ‚ÄúRemind me to send the proposal Friday at 3 PM‚Äù). We‚Äôll capture these requests either via the web UI (a quick ‚ÄúAdd Reminder‚Äù form) or via a Slack message to the bot. AmayAI parses the request (likely using an LLM to extract the task and date/time) and creates a new task in the user‚Äôs Google Tasks with the due date/time. Proactive reminders come from AmayAI‚Äôs own analysis ‚Äì for example, if it sees an unpaid invoice email, it might create a reminder ‚ÄúFollow up on invoice #123‚Äù for next week (after asking the user). In both cases, the task is stored in Google Tasks, and possibly also logged in our database for tracking. When a task‚Äôs due time arrives (or a scheduled reminder time hits), AmayAI will send the user a Slack direct message to make sure they see it immediately. (For example: ‚Äúüîî Reminder: call the supplier now.‚Äù) This replaces the need for sending SMS or making a phone call as Martin might have done. The Slack message can be generated by our backend when the time comes, or we can schedule it in advance using Slack‚Äôs API. Once sent, AmayAI can mark the task as ‚Äúcompleted‚Äù or add a note if appropriate. AmayAI can also provide daily or weekly briefing messages. For instance, every morning at 8 AM it could compile: ‚ÄúToday‚Äôs schedule: 3 meetings (first one at 9 AM), 2 tasks due, and 5 unread important emails.‚Äù This briefing could be delivered via Slack DM or email. Implementation-wise, this could be a scheduled cron job that queries the user‚Äôs Calendar and Tasks for the next day or week, summarizes them (possibly using the LLM to highlight what‚Äôs important), and then sends out a formatted message. Initially, a simple summary without AI might suffice (just list events and tasks). Implementation Steps:
Capture Reminder Requests: Allow users to input reminders. In the web app, include a quick ‚ÄúAdd reminder/to-do‚Äù interface. In Slack, the user could message the bot (e.g., ‚Äúremind me to...‚Äù) or use a slash command. Use an LLM to parse natural language inputs into a structured task (e.g., task description and due date) when needed.
Create Task via API: Use the Google Tasks API to insert a new task for the user with relevant details (title, notes, due date/time). For simple date-based reminders, we could alternatively use Calendar events, but Tasks is suitable and keeps these to-dos separate from hard calendar events.
Scheduling the Notification: Decide how to trigger the reminder notification. The straightforward approach is for the backend to track due times (e.g., poll or use a scheduled job). For example, every minute a background job checks for any task due in the next minute and sends the Slack DM. This can be implemented with a lightweight scheduler (Cloud Scheduler or even a loop on the server) or using Slack‚Äôs ability to schedule messages in advance.
Slack DM Reminder: When it‚Äôs time, compose a Slack message to the user with the reminder text. Use the Slack Web API (chat.postMessage or chat.scheduleMessage) to send it to the user‚Äôs DM channel. We‚Äôll need the user‚Äôs Slack ID and the bot token (see Slack Integration below) to do this. The message should be succinct and clear (possibly include the task title and due time).
Mark Complete (Optional): If we want to auto-cleanup, after sending a reminder we could mark the task as completed in Google Tasks via the API, or we might leave it for the user to check off. At minimum, we should not send duplicate reminders, so ensure each task is only reminded once (we could update a metadata field or our own log to indicate it was sent).
By plugging into Google Tasks, we avoid needing any external task management service ‚Äì everything stays within the Google ecosystem. The user benefits by having a single source of truth for tasks, and Slack DMs ensure the reminders are seen in real time. For recurring reminders (like ‚Äúevery Monday 9am send report‚Äù), we could either use Slack‚Äôs recurring reminders or store it as a recurring task and handle it accordingly, but that can be an extension. The key is that AmayAI will make sure no important to-do is forgotten.
Slack DM Notifications (Replacing Calls & Texts)
In the original Martin system, the assistant could place phone calls or send SMS/WhatsApp messages to get your attention or relay information. In our company-focused clone, we will replace those channels with Slack direct messages. Slack is our team‚Äôs primary communication tool, so it‚Äôs both effective and appropriate to use for AmayAI‚Äôs alerts and interactions. This means any reminder, prompt, or urgent update from AmayAI will come as a DM from a Slack bot (AmayAI‚Äôs persona) rather than a text or call. It also means employees can interact with AmayAI by messaging the bot on Slack, just like they would message a human assistant. Using Slack for notifications has several benefits: it‚Äôs instant, it‚Äôs less intrusive than a phone call, and it keeps a written record. For example, if AmayAI needs to nudge a user about something (‚ÄúYou have an unread alert that looks like a bill ‚Äì should I add a reminder?‚Äù), it can send a Slack message with that question. The user can then respond in Slack or click a button, and the assistant can act accordingly. Slack DMs will also be used for delivering reminders (‚ÄúDon‚Äôt forget your 1 PM meeting‚Äù) and daily briefings as discussed. Essentially, Slack becomes AmayAI‚Äôs voice. From an implementation standpoint, we will create a Slack bot user for AmayAI inside the company‚Äôs Slack workspace. With the proper permissions, this bot can initiate DMs with any user in the workspace and post messages. All it takes is a single Slack OAuth token for the bot ‚Äì no need for per-user Slack auth unless we want to receive messages (we‚Äôll cover options in Slack Integration section). The heavy lifting of OAuth and identity mapping we‚Äôve done for Google doesn‚Äôt conflict with Slack‚Äôs model at all; we can comfortably use both APIs side by side. How it works: Once the Slack app (bot) is set up and installed for the workspace, our backend will use Slack‚Äôs Web API to send messages. Each user is identified by a Slack user ID (like U12345) ‚Äì AmayAI needs to know each user‚Äôs Slack ID to DM them. We can obtain that either by asking each user to authenticate Slack once (to link their Slack account, retrieving their user ID) or by using the Slack admin APIs to look up users by email (if the Slack profile emails match their Google email). For simplicity, we assume the latter: we can call Slack‚Äôs users.lookupByEmail method (or the newer users.identity with an admin token) to get a user‚Äôs Slack ID from their email address. Since all our users use their @cmacroofing.com email in Slack, this mapping should be reliable. Whenever AmayAI needs to notify someone (for a reminder, nudge, etc.), the backend will form the message text and call chat.postMessage with the Slack user ID as the target channel. Using a user‚Äôs Slack ID as the ‚Äúchannel‚Äù in a Slack API call will send a DM to that user from our bot. For example, our request might be: chat.postMessage with JSON body { "channel": "U0ABC1234", "text": "Heads-up: your next meeting starts in 10 minutes." }. Slack will deliver that as a direct message from AmayAI to the user. We can also include rich formatting or even interactive buttons in these messages (for future enhancements like ‚ÄúComplete task‚Äù buttons). AmayAI will also listen for user messages on Slack if we choose to support that. This means if a user DMs the AmayAI bot with a request (‚Äúschedule a meeting with Bob next week‚Äù or ‚Äúwhat‚Äôs my day look like?‚Äù), we would receive that via a Slack events API and can respond accordingly. Supporting incoming messages requires adding a bot event subscription (and possibly a slash command for structured commands), and it will involve parsing the user‚Äôs message (again likely with the LLM) to figure out the intent. This is a stretch goal, but it aligns with Martin‚Äôs design of being reachable on any channel. Initially, our Slack integration can be one-directional (assistant -> user notifications), but it‚Äôs good to design with two-way in mind, as it greatly enhances usability. Implementation Steps:
Slack App Setup: Register a Slack app for AmayAI in the company Slack workspace. Grant it minimal scopes needed: at least chat:write to send messages and im:write to open IM channels (DMs) proactively. If we plan to use Slack‚Äôs reminder feature or need to set reminders, also add reminders:write (optional). Install the app to the workspace and obtain the Bot User OAuth Token (usually starts with xoxb-...). This token will be used by our backend to authenticate to Slack‚Äôs API.
Store Credentials Securely: Save the Slack bot token in a secure manner (e.g., as an environment secret or in a secure key vault). The backend code will load this token to authorize Slack API calls. Never hard-code it. (In production, Google Secret Manager or similar can be used to store secrets safely.)
User ID Mapping: Establish how to get each user‚Äôs Slack ID. The easiest method is to use the Slack Web API method users.lookupByEmail with an admin token, which requires an admin scope or token. Alternatively, perform a one-time OAuth for each user: when the user logs into AmayAI‚Äôs web app, also have them authorize Slack and record their Slack user ID. For now, assume we can map by email without bothering the user (since all users share the domain and Slack likely has their emails). We will need either a Slack token with the right permissions to do this lookup or we can maintain a manual mapping if trivial.
Sending Messages: Implement a utility in the backend to send Slack DMs. Using the bot token, call Slack API methods like chat.postMessage to send immediate messages. For scheduled notifications, consider using chat.scheduleMessage to schedule a DM for a specific time (Slack will then send it at that time without our server needing to wake up). For recurring notifications (like daily briefings), either schedule them each day via chat.scheduleMessage or use a server-side scheduler (e.g., a daily cron job that calls chat.postMessage each morning).
Testing and Fail-safes: Test sending a message to a known user ID to verify the bot can DM. Ensure to handle errors (e.g., if a user ID is wrong or the bot isn‚Äôt invited to a channel). Since the bot is in the workspace, it should be able to DM any user by default. Also, implement some logging for messages sent, so we have an audit trail.
With Slack notifications in place, users will get timely updates from AmayAI in a non-intrusive way. This approach leverages Slack‚Äôs reliability and avoids building a separate notification system. It effectively replaces SMS/text reminders with Slack DMs, aligning with company practice. In terms of user experience, after a while, interacting with AmayAI on Slack should feel as natural as chatting with a colleague ‚Äì they can ask it for help or expect it to ping them when needed.
Proactive Nudges (AI-Driven Suggestions)
One of the powerful aspects of having an AI assistant embedded in your workflow is that it can proactively assist you without being asked. AmayAI will include a ‚Äúproactive help‚Äù engine that observes patterns in your emails, calendar, and tasks and suggests helpful actions. Martin‚Äôs system does this too ‚Äì for example, if it notices ‚ÄúYou have an unread bill-pay alert‚Äù, it might ask if you want a reminder set for it. For our implementation, proactive nudges could cover scenarios relevant to our business context, such as:
Detecting that an important email from a client has gone unanswered for 3+ days, and prompting: ‚ÄúYou haven‚Äôt responded to [Client]‚Äôs email about XYZ. Would you like me to draft a follow-up?‚Äù
Noticing back-to-back meetings on your calendar and suggesting to block out some focus time or prepare materials.
Spotting that a meeting is scheduled without a conference link or location and offering to add one.
Finding tasks that are overdue and nudging the user to update or reschedule them.
How it works: The proactive engine will run periodically (perhaps once a night or during off-peak hours) and use the LLM to analyze recent user activity for potential issues or opportunities. Concretely, we might have a nightly job that looks at the past 30 days of emails and calendar events, plus upcoming events, using lightweight queries: e.g., fetch emails that are still unread or not replied to, get calendar events for the next week. We then feed a summary of this data to the LLM with prompts to identify anything noteworthy: for example, ‚ÄúAmong these, find any situations where something might need the user‚Äôs attention that they have not addressed.‚Äù The LLM can be instructed to output suggestions like ‚Äúunanswered invoice from X‚Äù or ‚Äúmeeting tomorrow with no agenda.‚Äù This is essentially an AI-driven analysis of the user‚Äôs workflow patterns. Once the AI highlights potential items, AmayAI will generate suggestion cards for the user. In the web dashboard, there could be a section ‚ÄúProactive Suggestions‚Äù listing things like:
‚ÄúYou have 2 unanswered client emails from last week. [View Emails] [Draft Replies]‚Äù
‚ÄúYour project kickoff meeting with ABC Corp has no agenda. [Add Agenda]‚Äù
‚ÄúIt‚Äôs been 1 month since you last updated the CRM. Shall I schedule a reminder to do that?‚Äù
Each suggestion would give the user an option to act (one-click actions like drafting a reply, adding a reminder, or ignoring the suggestion). These could also be pushed to the user via Slack DM for immediate notice, especially if time-sensitive (‚ÄúYou have a meeting in an hour with no deck attached ‚Äì want me to ping someone for it?‚Äù). Implementation Steps:
Periodic Analysis Job: Configure a scheduled job (e.g., a daily Cloud Run job or cron) that runs the proactive analysis. This job will use Google APIs to pull a slice of user data: for example, list of emails in the inbox or specific labels (like ‚Äúinbox‚Äù or ‚Äúunread‚Äù), and upcoming calendar events for the next few days.
LLM Prompting: Prepare a prompt for the LLM that provides metadata of these emails/events (we may not send full email bodies for privacy, maybe just subjects and dates or types) and asks the LLM to find any ‚Äúactionable‚Äù items or patterns. This might include logic like: find any unread emails that seem important, any email threads where the last incoming email was >5 days ago and user hasn‚Äôt replied, any upcoming meetings missing details, etc. The LLM can identify such patterns and respond with suggestions. If using OpenAI, this data will leave Google‚Äôs cloud, so ensure no highly sensitive info is included or use anonymized text. If that‚Äôs a concern, using Google‚Äôs Gemini model via Vertex AI could be an alternative ‚Äì it can be configured to respect data governance and PII rules, keeping analysis in-house.
Generate Suggestions: Parse the LLM‚Äôs output into structured suggestions. Each suggestion should have a description (‚Äúunanswered email from Alice about Contract‚Äù) and a recommended action (‚ÄúDraft a reply‚Äù or ‚ÄúSet follow-up reminder‚Äù). We might classify suggestions by type (email-related, calendar-related, task-related).
Surface to User: Add these suggestions to the user‚Äôs dashboard UI under a ‚ÄúProactive Nudges‚Äù section. For each, allow the user to take action or dismiss it. Additionally or alternatively, send a Slack DM summarizing the suggestions, especially if it‚Äôs something the user might want to address soon. For example: ‚ÄúI noticed 2 potential tasks for you: [details]. Check the AmayAI dashboard for quick actions.‚Äù
Learning and Tuning: As the user accepts or dismisses suggestions, the system can learn what types of help are useful. We can refine the LLM prompts or filtering criteria over time to reduce noise. In early versions, we might keep the scope narrow (e.g., only look for obviously important things like emails from VIP contacts).
The proactive help engine essentially turns AmayAI from a passive tool into a more agent-like assistant. It‚Äôs continuously looking out for the user‚Äôs interests, which can significantly improve productivity (like a smart executive assistant who anticipates needs). Because this involves scanning user data, we must implement it with respect for privacy and with the option for the user to turn it off if desired. But given it uses the same data the user already has access to, and it runs internally, it should be a welcome aid. Technically, this feature is an extension of the core pieces (email, calendar, LLM) with some pattern-recognition logic layered on top.
Google Workspace Integration (Gmail, Calendar, Tasks)
To achieve the above functionality, AmayAI will deeply integrate with Google Workspace services: primarily Gmail, Google Calendar, and Google Tasks. All user data and actions are handled through these Google APIs, which means we don‚Äôt need any external systems for email, scheduling, or task management ‚Äì we piggyback on Google‚Äôs infrastructure. The key design decision here is to use a Google Cloud service account with domain-wide delegation to access user data centrally. Service Account & Domain-Wide Delegation: We will create a service account in Google Cloud that has domain-wide access to the company‚Äôs Google Workspace data (restricted to specific scopes). Domain-wide delegation allows our backend to impersonate any user in the domain when calling Google APIs, with admin-granted permission. In practice, this means our server can perform actions on behalf of alice@cmacroofing.com or bob@cmacroofing.com by using the service account‚Äôs credentials and specifying the target user. This approach eliminates the need for each user to individually OAuth-consent to Gmail/Calendar access; instead, the Google Workspace admin consents one-time for the whole domain for certain data scopes. As long as we include a ‚Äúsubject‚Äù (impersonated user email) in our API requests, Google knows to access that user‚Äôs data. For example, if the service account is set up properly, our code can do something like:
python
Copy
creds = service_account.Credentials.from_service_account_file("svc.json", 
    scopes=["https://www.googleapis.com/auth/gmail.modify"], 
    subject="alice@cmacroofing.com")
gmail_service = build("gmail", "v1", credentials=creds)
gmail_service.users().messages().list(userId="me", q="is:unread").execute()
In this snippet, by setting subject="alice@cmacroofing.com", the Gmail API call will fetch Alice‚Äôs unread emails. If we change the subject to Bob, the same credentials now operate on Bob‚Äôs mailbox. This is incredibly powerful: one service account key can access all mailboxes/calendars, but only one at a time and only for the scopes granted. It never has blanket access without impersonation, and it never uses the admin‚Äôs account or password ‚Äì it‚Äôs all through delegated OAuth tokens. We will request delegation for Gmail, Calendar, and Tasks APIs. The exact OAuth scopes likely include: Gmail read/write (gmail.modify which covers reading and sending emails), Calendar read/write (calendar.events scope), and Tasks read/write (tasks scope). The domain admin (Cody) will whitelist these scopes for our service account‚Äôs client ID in the Google Workspace admin console. This setup is a one-time thing ‚Äì once configured, our backend can impersonate any user in the domain to call those APIs without further user consent. Using the Google APIs: With delegation in place, AmayAI‚Äôs backend essentially acts like each user‚Äôs personal agent on Google. The major Google APIs we‚Äôll use are:
Gmail API ‚Äì for reading emails, searching threads, sending emails (replying), applying labels, and watching for new messages. We‚Äôll use endpoints like messages.list, messages.get, messages.send, and Gmail push notifications.
Calendar API ‚Äì for checking availability (FreeBusy query), creating and updating events, and reading events (for proactive checks or briefings). Endpoints include events.insert, events.list, and freeBusy.query.
Tasks API ‚Äì for creating and managing to-do items and reminders. Endpoints include tasks.insert, tasks.list, etc., under the user‚Äôs default task list (or a designated list for AmayAI if we prefer).
People API (optional) ‚Äì we might use the Google People API (or Directory API) to get information about contacts or coworkers, e.g., to fetch a user‚Äôs contacts when drafting an email, or to translate names to emails. This is not core, but it could be handy for things like ensuring we have correct email addresses or for later enhancements (like if the assistant is asked ‚Äúwho is John Doe?‚Äù, it could look up the company directory).
Google Drive API (optional) ‚Äì not in scope for now, but if in the future AmayAI needs to fetch or insert attachments (like finding a file to attach to an email), we might integrate Drive. For now we will not request Drive scope (principle of least privilege).
All these API calls will be made by our backend server. Thanks to the service account impersonation, we‚Äôll handle authentication transparently. The user will likely log into the AmayAI web app with Google OAuth as well (for front-end side authentication), but that is just to verify their identity and perhaps to get basic profile info; the heavy data operations will use the service account in the backend. Data Flow Example: To illustrate, consider the email triage flow for a user (say Alice). Alice logs into the AmayAI web app via Google Sign-In, so we know her email. We subscribe to Gmail push notifications for Alice‚Äôs mailbox using the service account (with subject Alice). When a new email comes in, Google sends a notification to our webhook. Our backend receives it and knows it‚Äôs for Alice‚Äôs inbox. We then initialize credentials with subject=Alice and call Gmail API to get the email. We process it and perhaps call the LLM. Then we might call Gmail API again (still as Alice) to apply a label or send a reply draft. All of these calls use the single service account key, just switching the ‚Äúsubject‚Äù each time for different users. This design scales to multiple users easily ‚Äì the only limitation is we must always remember to specify the correct user‚Äôs email as the subject on each API call. If we forget, the API will return an error because the service account itself doesn‚Äôt have a mailbox or calendar. Advantages of this approach: It centralizes integration and is IT admin-friendly. We don‚Äôt have to worry about token storage per user or refreshing dozens of OAuth tokens ‚Äì just one service account credential to manage. It‚Äôs also secure when configured correctly: the service account can only access the scopes granted. We will ensure to request the minimum scopes necessary (for example, we might use a Gmail scope that allows reading and sending but not full mailbox settings access). The admin can audit or revoke the service account‚Äôs access at any time from the admin console. And any API action we take can be logged for compliance (we can log which user we impersonated and what we did, to have an audit trail). Finally, using Google‚Äôs own APIs means we inherit a lot of power out-of-the-box: search in Gmail, event invites in Calendar, etc., come for free. We just orchestrate them. Google‚Äôs reliability and security (OAuth scopes, data in transit encryption, etc.) apply to all these interactions. In essence, we are building on top of Google Workspace as a platform.
AI Integration: OpenAI GPT-4 (or Google Gemini)
AmayAI‚Äôs ‚Äúbrain‚Äù for understanding language and generating smart outputs will be a Large Language Model. This is what enables features like summarizing emails, drafting replies, parsing instructions, and finding patterns. We have two primary options: OpenAI's GPT series or Google‚Äôs new Gemini model via Vertex AI. The choice can be left to implementation or even abstracted (developers could write a service with a pluggable LLM backend). Both have pros and cons:
OpenAI GPT-4/GPT-3.5: These models are state-of-the-art in language understanding and generation. GPT-4 in particular is known for high-quality, coherent outputs and is already used in similar products (Martin itself uses ‚ÄúGPT-4-class models‚Äù under the hood, and tools like Superhuman‚Äôs AI Reply use OpenAI). Using OpenAI‚Äôs API is straightforward: we send the model a prompt and get a completion. OpenAI also supports features like function calling, which could be useful (e.g. we can have the model extract structured data like dates or classification tags by defining a function schema). The downside is data governance ‚Äì sending content to an external API (OpenAI‚Äôs servers) might raise privacy considerations, though OpenAI offers policies for data usage. Also, cost and rate limits must be considered, but for a corporate assistant with moderate volume, this should be manageable.
Google Gemini (via Vertex AI): Google‚Äôs own family of next-gen models (Gemini) are accessible through Google Cloud‚Äôs Vertex AI platform. By the time of this project, Gemini 2.x may be available. Using Gemini could keep more data within the Google Cloud environment, which might be preferable for privacy ‚Äì especially since our data is from Google Workspace, processing it with Google‚Äôs AI might ensure it stays under Google‚Äôs compliance umbrella. Vertex AI also allows setting data governance policies (like not logging prompts that contain PII). However, at present, OpenAI‚Äôs models are often regarded as more capable/mature in many language tasks. Gemini is improving rapidly, but if we need best-in-class quality now, GPT-4 might be the pick. We could even implement a strategy: start with OpenAI (for proven results) and plan to shift to Gemini in the future when it‚Äôs on par or if data residency becomes a concern.
LLM Usage in AmayAI: We will use the LLM for several distinct tasks:
Summarization: Summarize email threads or long emails into concise bullets or a sentence. (Used in inbox triage and daily briefings.)
Draft Generation: Generate possible email or message replies given context. (Inbox drafting, possibly Slack message drafting for suggestions.)
Classification/Prioritization: Determine the nature or urgency of content. For instance, classify an email as urgent vs low-priority, or identify if an email is a request, an FYI, a calendar invite, etc.
Intent Parsing: Understand user commands or requests given in natural language (through Slack or voice/text inputs). For example, parse ‚ÄúRemind me to call John next Monday‚Äù into structured data (task: call John, date: next Monday).
Pattern Recognition: Analyze user‚Äôs data for proactive suggestions, e.g., identify an ‚Äúunanswered invoice email‚Äù or ‚Äúmeeting with no agenda‚Äù as we described in nudges.
Each of these use cases may involve slightly different prompting techniques:
We might fine-tune or write specialized prompts. E.g., for email triage: ‚ÄúYou are an assistant. Summarize the email thread below in one sentence, and draft three brief reply options.‚Äù including the thread text.
For scheduling, we might use the model‚Äôs reasoning to extract possible meeting times from text, or even to interpret a vague request like ‚Äúsometime in early next week‚Äù.
For parsing tasks/reminders, a prompt could be like: ‚ÄúExtract the action, date, and time from this request: ‚ÄòRemind me to submit the report on Nov 5th at 9AM‚Äô.‚Äù
For proactive scanning, we might feed a list of recent email subjects and ask: ‚ÄúDo any of these look like something the user might need to follow up on?‚Äù
The developers should leverage the chosen LLM‚Äôs strengths. If using OpenAI, GPT-4 is recommended for its better understanding, especially for drafting professional emails or handling tricky language in scheduling. If budget is a concern, GPT-3.5 Turbo can handle many tasks reasonably well (perhaps summarization and straightforward replies). If using Google‚Äôs Vertex AI (Gemini), they may have specific models or tuning options for enterprise use ‚Äì for instance, a model optimized for email/chat might be available. Integration Details:
OpenAI API: We‚Äôll obtain an API key and use OpenAI‚Äôs REST endpoint (or their Python/Node SDK) to send prompts. We must be mindful of token limits (ensure prompts aren‚Äôt excessively long ‚Äì possibly truncate long email threads or use conversation history strategically). Also, incorporate error handling and fallbacks (if the API is down or returns an error, the system should handle gracefully, maybe retry or default to not drafting).
Vertex AI API: If we go this route, we‚Äôd use Google Cloud‚Äôs SDK to call the Vertex AI models. This requires enabling the API in our GCP project and having the service account granted permission to use it. The calls would similarly send text and receive a completion. Latency and performance should be tested for whichever model we use.
We do not need to hard-commit to one model in the design. We can abstract the LLM calls behind a service interface so that switching from OpenAI to Gemini or vice versa is not too difficult. Initially, using OpenAI might get us results faster (given known examples and documentation), but we‚Äôll keep an eye on Gemini‚Äôs capabilities. Security-wise, whichever LLM we use, we should avoid sending extremely sensitive information in prompts if possible. Since this is an internal tool, most data is internal anyway, but for example, if an email contains personal identifiable info or confidential data, that will be going to the LLM provider. If that‚Äôs a problem, one could choose Gemini (keeping data in Google Cloud, assuming Google is a trusted environment for this company) or filter out certain content from prompts. At least, we should document this aspect so the company is aware and can make an informed decision or add an agreement with OpenAI if needed. In summary, the LLM is a crucial component that gives AmayAI its ‚Äúsmarts.‚Äù We will use it for language understanding and generation tasks throughout the application. The development team has flexibility in choosing the model, but must integrate its API carefully and ensure responses are handled appropriately (always have a reasonable default if the LLM produces something unusable).
Slack Integration (Notifications & Commands)
Integrating Slack is essential for AmayAI to communicate with users in real time. We‚Äôve outlined how Slack DMs will be used in the features above; here we provide more detail on setting up and using the Slack API as developers. Slack Bot Setup: We need a Slack app (bot) with the ability to send direct messages to users. Cody or an admin will create this Slack app in the company‚Äôs Slack workspace (via api.slack.com). The app should be given the following OAuth scopes:
chat:write ‚Äì allows the bot to post messages in channels and DMs.
im:write ‚Äì allows opening a DM channel with a user (so the bot can initiate a conversation if it hasn‚Äôt already).
reminders:write ‚Äì (optional) if we want to use Slack‚Äôs built-in reminders (not mandatory, as we can handle reminders ourselves, but available).
We do not need broad scopes like reading channel history or user info for our current requirements, which keeps the app limited in access (good for security). Once scopes are set, the app is installed to the workspace. During installation, Slack will provide an OAuth access token for the bot (starting with xoxb-...). We‚Äôll capture that token for use in our backend. We should also note the Signing Secret Slack provides, in case we set up any interactive components or event subscriptions (used to verify Slack‚Äôs requests).
Messaging Users: To send a DM, we need the Slack user‚Äôs ID (a string like UXXXX12345). As discussed, we can map users by email or ask them to connect Slack. A quick approach is to use Slack Web API method users.lookupByEmail (which requires the bot token plus the users:read.email scope or an admin token). Alternatively, Slack‚Äôs newer apps don‚Äôt easily expose users.lookupByEmail to bots without a User token, so another trick is: have a small ‚ÄúSign in with Slack‚Äù button in AmayAI for users to click, which does a Slack OAuth flow granting identity.basic just to get their user ID. Another approach is Slack‚Äôs SCIM API or company directory if available, but that might be overkill. For now, plan on a one-time mapping: either manual input or using email matching. The development team can decide which method is simpler given the environment (e.g., if only a few users, mapping by hand is fine; if many, an automated lookup is better). Once we have a user‚Äôs Slack ID, sending a message is done via HTTP POST to Slack‚Äôs endpoint chat.postMessage with JSON payload containing the channel (user ID) and message text (and token in header). We can use Slack‚Äôs official SDK (for Node or Python) to simplify this call. For example, using Python pseudocode:
python
Copy
slack_client = SlackClient(bot_oauth_token)
slack_client.chat_postMessage(channel=user_id, text="Your meeting starts in 10 minutes.")
This will drop the message into that user‚Äôs DM with the bot. If the bot has never spoken to the user before, Slack will automatically create a new DM channel (thanks to im:write scope) so the user sees it. We should also handle the case of scheduling messages:
For one-off future notifications, Slack provides chat.scheduleMessage where we provide a Unix timestamp for the future send time. This is very handy for reminders: when we create a reminder task due at 5pm, we can immediately schedule a Slack message for 5pm. Slack will then deliver it at that time, even if our app is not running or is busy ‚Äì no need for us to manage a timer. The limitation is these are one-shot; for repeating reminders, we‚Äôd have to schedule each occurrence separately (or use Slack‚Äôs recurring reminders).
For recurring notifications (like daily briefing), Slack‚Äôs reminders.add could be used (this sends via Slackbot, not our bot, and the reminders show up slightly differently). Alternatively, simply use an external scheduler (like a daily cron job in our backend) to send the message every day. The blueprint recommendation is that for quick nudges, using Slack‚Äôs scheduling is simplest, and for anything more complex, handle it on our side. We can follow that: use chat.scheduleMessage liberally for simplicity.
Receiving Messages (Optional): If we want AmayAI to respond to Slack messages from users, we will set up a Slack Events subscription on the app. This requires hosting an endpoint (which our web app backend can provide) and verifying it with Slack. We‚Äôd subscribe to message events (specifically direct message events to the bot). Whenever a user sends something to the bot, Slack will POST the event to our endpoint. Our backend then needs to parse the text and decide what to do (likely feed it to the LLM or interpret commands). For example, if user DMs ‚Äúschedule meeting with Bob tomorrow at 2‚Äù, our backend could parse that and trigger the scheduling workflow. Implementing this would involve adding event.subscriptions scope and a bit more code, but it‚Äôs not strictly needed for initial functionality if we focus on output notifications. However, since the assistant is more useful if it can be summoned on Slack, it‚Äôs worth keeping in mind as a near-term enhancement. Slack App Configuration Summary:
App Name: e.g. ‚ÄúAmayAI Assistant‚Äù.
Bot Username: e.g. ‚ÄúAmayAI‚Äù (so DMs come from ‚ÄúAmayAI‚Äù).
Scopes: chat:write, im:write (+ maybe commands if using slash commands, reminders:write optional).
Redirect URLs: If using OAuth for user identity, set the redirect URL to our web app‚Äôs callback.
Event Subscriptions: If enabling, subscribe to message.im events (direct messages).
Interaction Settings: If we use interactive buttons in Slack messages, we‚Äôll need to set an endpoint to receive those actions as well.
Finally, we must ensure to treat Slack credentials securely and follow best practices:
Keep the bot token secret (it grants the power to post as the bot in our workspace).
Do not hard-code channel IDs or user IDs; always look them up or configure them.
Log Slack errors for troubleshooting (e.g., if a message fails because user has left the company, we‚Äôd know why it wasn‚Äôt delivered).
Respect rate limits: Slack allows a certain number of messages per second; our use (a few per user per day perhaps) is low-volume, but be mindful in code (the Slack SDKs handle rate-limits internally typically).
With Slack integration properly set, AmayAI will effectively have a real-time communication line to each user. This dramatically increases its usefulness (no need for the user to constantly check a separate app; they get notified on Slack about whatever is important). It also means we can gradually add interactive capabilities on Slack, turning it into another interface for the assistant alongside the web app.
Web App Interface (Dashboard)
AmayAI will initially be delivered as a web application (with plans for an iOS app later). The web interface is where users can log in, view what the assistant has done or suggested, and interact with those items. We should design it as a dashboard for the user‚Äôs day, integrating the various features: Key elements to include on the web UI:
Inbox Triage Dashboard: A section showing new emails or threads that have been processed by AmayAI. For each thread, display the AI-generated summary and any draft replies. Let the user click to open the full email (maybe via a link to Gmail or an in-app viewer), and have buttons like ‚ÄúSend this draft‚Äù or ‚ÄúIgnore‚Äù. This makes it easy to blast through emails by just approving drafts or reading summaries.
Tasks/Reminders List: A to-do list view showing the user‚Äôs current tasks and reminders (fetched from Google Tasks). This could be integrated with the email view (e.g., a button to create a task from an email) or standalone. Allow adding a new task/reminder from here as well. Indicate which ones were added by AmayAI proactively.
Calendar Overview: A mini calendar or list of today‚Äôs events, possibly with any scheduling actions AmayAI took. (E.g., ‚ÄúMeeting with Client X ‚Äì scheduled by AmayAI‚Äù). This reminds users of their schedule and shows that AmayAI is keeping their calendar organized.
Proactive Suggestions: As described, a section for ‚ÄúWould you like me to‚Ä¶?‚Äù suggestions that the assistant has generated. Each suggestion might have an action button (like ‚ÄúYes, do it‚Äù which could trigger the assistant to execute the suggestion).
Settings/Preferences: Some interface for the user to adjust preferences. Early on, this might just be minimal (maybe a toggle for ‚Äúsend me daily briefings‚Äù or ‚Äúallow proactive suggestions‚Äù). Also possibly a ‚ÄúConnect Slack‚Äù button if we do user-specific Slack OAuth. Additionally, an option to disconnect or log out, etc.
Because it‚Äôs internal and for a controlled set of users, we don‚Äôt need an overly polished UI at first, but it should be clean and not confusing. Using a modern web framework will help build this quickly. The developers are free to choose the stack ‚Äì for example, a React-based single-page application would work well. The blueprint suggestion was Next.js or Remix (React frameworks with good support for server-side rendering and integrating with OAuth), but it‚Äôs ultimately the team‚Äôs choice. What is important is implementing Google OAuth login on the web app: users should sign in with their Google Workspace credentials (we can restrict OAuth to the company domain). This gives us their identity securely and can also provide a Google ID token if needed for some API calls (though mostly we use the service account for data, not the user‚Äôs token). Steps for the web app:
Authentication: Use Google‚Äôs OAuth 2.0 to sign users in. Register the app in Google‚Äôs API console to get a Client ID for OAuth (since it‚Äôs internal, this might be a ‚Äúinternal app‚Äù in Google‚Äôs terms). Request at least the profile and email scopes to get the user‚Äôs email. We might not need to request Gmail/Calendar scopes here because the service account covers data access ‚Äì the OAuth is just for authentication (and maybe verifying they belong to the domain). Once authenticated, establish a session (could be a secure cookie or token) so the backend knows which user‚Äôs data to show (e.g., user ID or email in session).
Impersonation linkage: When the backend receives a request from a logged-in user, it knows the user‚Äôs email (from session or token). It will then use the service account credentials with that email as subject to fetch data. For instance, when the front-end calls an endpoint to get ‚Äútriage results‚Äù, the backend will impersonate that user to query Gmail or our database for stored summaries.
Real-time updates: Ideally, the dashboard updates as new things happen (new email arrives, a reminder triggers, etc.). We can implement a simple WebSocket or use a service like Firebase/Firestore if we had one. A lightweight approach is for the backend to push notifications via WebSocket to the front-end when, say, a new triaged email is ready, or a suggestion was generated. This avoids the user having to refresh. However, initially it could be acceptable to refresh the page or have the front-end poll every few minutes. Given the context, using a WebSocket or Server-Sent Events could be a nice touch (the blueprint mentioned possibly using Pub/Sub and WebSockets for real-time updates).
No Mobile Yet: We explicitly note that a native iOS app will be built later, so we do not need to accommodate mobile-specific functionalities beyond making sure the web app is responsive for mobile browsers. However, we should design our backend with an API structure that could be reused by a mobile app. For example, the backend might have REST endpoints or GraphQL that the web app uses to fetch data; an iOS app could use the same endpoints. So, it‚Äôs wise to keep the web front-end somewhat decoupled from the logic (maybe the front-end calls a REST API which our backend service provides). Replit devs can certainly just build a combined app (depending on language, maybe a Next.js that serves API routes and front-end together). The main point is: don‚Äôt lock into something that makes a future mobile app integration difficult. Using standard protocols and having a clear separation of front-end and back-end logic will help.
Google Workspace Add-on (Future): As an aside, Google offers the ability to create Workspace Add-ons that appear inside Gmail or Calendar UI. This could be a way later to integrate AmayAI directly into Gmail‚Äôs sidebar for users. It‚Äôs not needed now, but we mention it because we should not build anything that precludes that path. If our backend is accessible via HTTPS and we have the right integration points, we could reuse a lot of the code in an add-on. For now, we focus on the standalone web app.
In terms of framework/language, the developers have freedom. They can use a Python Flask/Django backend with a React front-end, a Node/Express backend with React or even a full-stack Next.js that handles both server and client. We do not enforce any particular framework here ‚Äì whatever allows rapid development and easy maintenance is fine. The only requirement is that it fulfills the integration points (Google OAuth, calling Google APIs, Slack API, and LLM API). To summarize, the web app is the control center for the user‚Äôs interactions with AmayAI. It should be designed to clearly present AI-generated assistance (so the user trusts and benefits from it without confusion), and to allow the user to give feedback or instructions easily. A clean, uncluttered UI with logical sections (Email, Calendar, Tasks, Suggestions) will likely work well. The dev team should leverage existing UI components or libraries for things like a calendar view or list management to speed up development.
Security and Best Practices
Building an assistant that has access to communication and schedule data means we must take security seriously. Here are key security considerations and best practices for AmayAI:
Least Privilege OAuth Scopes: When configuring Google Workspace API access, only request the scopes absolutely necessary for functionality. For example, use Gmail scopes that allow reading and sending email, but not deleting or settings if not needed. Avoid blanket scopes like https://mail.google.com/ (full access to Gmail) if a narrower scope like Gmail readonly plus Gmail send would suffice. The same goes for Calendar (perhaps only events scope) and Tasks. This limits the damage if credentials were misused and is better for compliance.
Secure Storage of Credentials: All sensitive keys and credentials (service account JSON key, Slack bot token, OpenAI API key, etc.) should be stored in a secure manner. On Replit, this means using the Secrets management (so they aren‚Äôt exposed in code). In production on GCP, one would use Secret Manager. Never commit these secrets to the repository.
Encryption in Transit: All API calls to Google, Slack, OpenAI, etc., are over HTTPS, which is good. The web app should enforce HTTPS as well (especially if deployed under a custom domain, ensure SSL).
Authentication & Session Security: Use secure cookies or tokens for the web app session. If using JWTs, sign them strongly. Ensure that only authenticated users (from the domain) can access the app ‚Äì possibly restrict Google OAuth to the company‚Äôs domain accounts. This prevents outsiders from even attempting to use the assistant.
Audit Logging: It‚Äôs a good idea to keep a log of significant actions the assistant takes on behalf of users. For instance, log every time an email is auto-sent or a meeting is scheduled, including who it was for and when. This can be just an internal log or even surfaced to the user (‚ÄúActivity log‚Äù) for transparency. On the admin side, Google‚Äôs audit logs can show API calls made with the service account, and Slack‚Äôs admin panel can show messages the bot sends. We should encourage reviewing those logs to ensure nothing fishy is happening. Since the service account can impersonate anyone, if its credentials were stolen, it would be serious ‚Äì so monitoring its usage is critical.
Impersonation Control: Only our backend servers should possess the service account key and be able to impersonate users. Never send the service key to the front-end or to users. Also, build safeguards in code ‚Äì e.g., only allow the service account to impersonate users within @cmacroofing.com domain, and only in response to authenticated user actions or system triggers. This prevents accidental misuse like impersonating an admin when not appropriate.
Rotating Keys: Consider periodically rotating the service account key and Slack token if feasible. Slack tokens can be set to automatically rotate (with a 12-hour window, requiring refresh logic), but that might be unnecessary for our internal tool scale. Still, if Slack offers short-lived tokens, we could implement refresh.
Compliance with Company Policies: Since this is internal, ensure that using an external LLM (OpenAI) is approved by the company. If not, stick to Google‚Äôs Vertex AI which might be covered under existing Google Workspace agreements. Also, ensure users know that an AI is reading their emails ‚Äì this might be obvious, but it‚Äôs good to communicate clearly so they aren‚Äôt surprised. Maybe include a one-time ‚Äúconsent‚Äù or information screen when they first use AmayAI.
Fail-safes: If for some reason the service account is revoked or an API quota is exceeded, AmayAI should handle it gracefully. For example, if Gmail API calls start failing, perhaps pause certain automations and alert an admin (or Cody). The user should never have a completely broken interface; degrade gracefully by maybe showing a message ‚ÄúUnable to fetch new data at the moment‚Äù if something‚Äôs wrong.
Testing in Sandbox: When building, test carefully with a limited scope before rolling out widely. Perhaps use a smaller subset of users or a separate Google Workspace sandbox domain to ensure everything works and is safe. The domain-wide delegation should first be tried with just one or two test accounts (impersonating yourself, etc.) to confirm that we‚Äôre not overstepping any boundaries.
By following these practices, we ensure that AmayAI remains a trustworthy tool inside the company. The power we‚Äôve given it (read/write across mailboxes, calendars, etc.) is substantial, but with that power comes responsibility to secure it. We have essentially one ‚Äúkey to the kingdom‚Äù (the service account key) ‚Äì protecting that is paramount.
Cody's Section ‚Äì Setup Checklist for Infrastructure
Before development can begin in earnest, there are several setup and configuration tasks that Cody (the client) needs to complete or provide. These ensure that the Replit developers have the necessary access and credentials to integrate all the services:
Google Cloud Project & Service Account: Create (or designate) a Google Cloud project under the company‚Äôs account to be used for AmayAI. In this project, create a Service Account that will be used by AmayAI for Google Workspace access. Enable Domain-Wide Delegation for this service account:
After creating the service account, generate a new JSON key for it (this will be given to the developers).
In the Google Workspace Admin Console, go to Security ‚Üí API Controls ‚Üí Domain-wide Delegation. Add a new delegation entry for the service account‚Äôs Client ID and grant it the scopes it will need. Specifically, include:
Gmail API scopes (e.g. https://www.googleapis.com/auth/gmail.readonly, .../auth/gmail.send, or use .../auth/gmail.modify for full mail access).
Google Calendar API scope (https://www.googleapis.com/auth/calendar for read/write).
Google Tasks API scope (https://www.googleapis.com/auth/tasks).
(Optional) Any other scopes if needed (e.g. if using People API for contacts, include .../auth/contacts.readonly).
Enable the APIs: In the Google Cloud project, ensure the Gmail API, Calendar API, and Tasks API are enabled (via APIs & Services dashboard). This is required for the service account to actually use those APIs.
Provide the service account JSON key file to the development team securely (e.g., via a secure sharing mechanism, not email). This key is what the backend will use to authenticate. It effectively grants the necessary access, so treat it like a password.
(If not already obvious, Cody must have super-admin rights on the Google Workspace domain to perform these steps.)
Slack App Creation: Set up a Slack App in the company‚Äôs Slack workspace for AmayAI:
Go to Slack API site (api.slack.com/apps) and create a new app (give it a name like ‚ÄúAmayAI‚Äù and tie it to the workspace).
Under OAuth & Permissions, add the following bot token scopes: chat:write and im:write. Also add reminders:write if you plan to use Slack‚Äôs reminder features. (No user scopes are needed unless doing a user OAuth flow.)
Install the app to the workspace (you might need to be a Slack admin to do this). Upon installing, you will receive a Bot User OAuth Token.
Copy the Bot OAuth Token (starts with xoxb-) and provide it securely to the developers. Also copy the Signing Secret from the Basic Information page (needed if the devs set up Slack event subscriptions or slash commands).
In the Slack app settings, if you know you want to support incoming commands, you can set up an Slash Command (e.g., /amayai) and/or enable Event Subscriptions (subscribe to bot DM messages). If not sure, this can be done later by the devs, but having the app in place with correct scopes from the start is important.
OpenAI API Key (or Google Vertex AI Access): Decide which LLM service will be used initially and ensure access:
For OpenAI: Create an account at OpenAI and generate an API key (from the OpenAI dashboard). If the company already has an OpenAI API subscription or keys, you can use that. The API key should be for a paid tier if using GPT-4 (as GPT-4 is usually not available on the free tier). Provide this secret API key to the development team (again, via a secure channel).
Make sure to enable billing for OpenAI usage, as needed, so that the API calls won‚Äôt hit a hard cap.
For Google Gemini/Vertex AI (if opting for Google‚Äôs LLM): Ensure the Google Cloud project has the Vertex AI API enabled. You may need to request access if it‚Äôs in preview or set up billing on the GCP project for Vertex AI usage. Also, ensure the service account has permissions to use Vertex AI (like the AI Platform User role). The devs will need either a service account JSON (they can use the same one if properly permissioned) or another method to authenticate to Vertex AI. Clarify which route you want to go (OpenAI vs Google) so the devs know which API to integrate.
If undecided, you can provide both (OpenAI key and Google project access) so developers can start with one and have fallback to test the other.
Assistant Email Address (for Scheduling): Create a dedicated user or alias in Google Workspace for the assistant‚Äôs email (e.g., amayai@cmacroofing.com):
The simplest is to create a full user account (licensed user) named ‚ÄúAmayAI‚Äù with that email. This mailbox will be used to send scheduling emails and to receive any direct emails to the assistant.
Alternatively, you could create an email alias on an existing account, but a separate user is cleaner. If it‚Äôs an alias, ensure the service account can access that mailbox via delegation (if alias is on an admin‚Äôs account, perhaps not ideal).
Once created, share the credentials of this account with the devs if they need to access it directly for testing (or they can access its mail via the service account anyway). At minimum, inform the devs of the chosen email address, so they know to programmatically watch that inbox for scheduling requests.
If you prefer not to create a new user, we can have the service account impersonate the requesting user for sending scheduling emails (so the user themselves sends the proposal). This is a design choice. But creating an ‚Äúassistant identity‚Äù might be nicer for clarity. Coordinate with the devs on which approach they will implement.
Environment for Development: Provide the Replit developers with any necessary access or environment setup on Replit:
They will need a way to securely store environment variables (Replit has a Secrets manager). Make sure they know the values (service account JSON, API keys, tokens) or have injected them.
If the development is happening on Replit, consider the implications of connecting to Gmail/Slack from that environment. Replit should allow outgoing API calls, but ensure no firewall or Google security setting is blocking it (sometimes new login attempts from unusual locations might trigger a security check ‚Äì using service account should bypass interactive login though).
Possibly create some test user accounts for them on the domain (or be ready to test with your account) so they can simulate a real scenario. If providing a test account, give them credentials or at least the email and set up delegation for it too (but domain-wide handles all users already).
Miscellaneous Settings:
Company Working Hours/Timezone: Communicate any default working hours or timezone that should be considered for scheduling logic. (The devs can default to something but if the company has specific hours or multiple time zones, that‚Äôs good to note.)
User Preferences Defaults: If there are any company-wide preferences (like ‚Äúdon‚Äôt schedule meetings on Fridays after 3 PM‚Äù or similar) that you know of, let the developers know so they can include such rules or make them configurable.
Slack Workspace Details: Ensure the Slack workspace allows custom apps (most do unless restricted). Also, decide which channels (if any) the bot might post to besides DMs (perhaps none for now). If you want the bot to potentially post to group channels (like a team reminder), it would need to be invited to those channels. For now, plan is only DMs.
Completing the above setup tasks will equip the development team with the infrastructure and credentials needed to start building AmayAI. Once these are in place, the developers can proceed with writing the code to integrate Gmail, Calendar, Tasks, Slack, and the LLM, according to the specifications in this document. Each item is critical: missing any (like